This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-01T16:01:44.641Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.gitignore
.python-version
pyproject.toml
README.md
src/mcp_dev_server/__init__.py
src/mcp_dev_server/docker/manager.py
src/mcp_dev_server/docker/streams.py
src/mcp_dev_server/docker/templates.py
src/mcp_dev_server/docker/volumes.py
src/mcp_dev_server/environments/manager.py
src/mcp_dev_server/environments/tools.py
src/mcp_dev_server/environments/workflow.py
src/mcp_dev_server/project_manager/context.py
src/mcp_dev_server/project_manager/git.py
src/mcp_dev_server/project_manager/manager.py
src/mcp_dev_server/project_manager/templates.py
src/mcp_dev_server/server.py
src/mcp_dev_server/utils/config.py
src/mcp_dev_server/utils/errors.py
src/mcp_dev_server/utils/logging.py
src/resources/templates/basic/files
uv.lock

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.env
.venv
env/
venv/
ENV/

# IDE
.idea/
.vscode/
*.swp
*.swo

# Project specific
*.log
.docker/
.pytest_cache/
.coverage
htmlcov/

================
File: .python-version
================
3.12

================
File: pyproject.toml
================
[project]
name = "mcp-dev-server"
version = "0.1.0"
description = "MCP Development Server for managing software development projects"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "mcp>=1.0.0",
    "gitpython>=3.1.0",
    "docker>=7.0.0", 
    "pydantic>=2.0.0",
    "anyio>=4.0.0",
    "jinja2>=3.0.0",  # Added Jinja2 dependency
    "inotify>=0.2.10",  # For container file monitoring
    "watchdog>=2.1.0"   # For enhanced file system events
]

[[project.authors]]
name = "Development Team"
email = "team@example.com"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project.scripts]
mcp-dev-server = "mcp_dev_server:main"

[tool.pylint]
max-line-length = 100
disable = ["C0111", "C0103"]

[tool.mypy]
python_version = "3.12"
strict = true
ignore_missing_imports = true

================
File: README.md
================
# MCP Development Server

A Model Context Protocol (MCP) server that enables Claude to manage software development projects, providing complete project context awareness and handling code execution through Docker environments.

## Features

### Core Infrastructure
- Project context management
- File system operations
- Template-based project creation
- Git integration

### Requirements
- Python 3.12 or higher
- Docker
- Git

## Installation

```bash
# Using pip
pip install mcp-dev-server

# Development installation
git clone https://github.com/your-org/mcp-dev-server.git
cd mcp-dev-server
pip install -e .
```

## Configuration

### Claude Desktop Configuration

Add to your Claude Desktop configuration file:

On MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`
On Windows: `%APPDATA%/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "dev": {
      "command": "mcp-dev-server",
      "args": []
    }
  }
}
```

## Usage

The server provides several MCP capabilities:

### Resources
- Project structure and files
- Build status and artifacts
- Test results
- Docker container status

### Tools
- Project initialization
- Build operations
- Test execution
- Docker commands

### Prompts
- Project analysis
- Development suggestions
- Error diagnosis

## Development

### Setting up development environment

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"
```

### Running tests

```bash
pytest tests/
```

## Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

================
File: src/mcp_dev_server/__init__.py
================
"""MCP Development Server Package."""
from . import server
import asyncio
from typing import Optional
from .utils.logging import setup_logging

logger = setup_logging(__name__)

def main():
    """Main entry point for the package."""
    try:
        server_instance = server.MCPDevServer()
        asyncio.run(server_instance.run())
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
    except Exception as e:
        logger.error(f"Server error: {str(e)}")
        raise

# Expose key components at package level
__all__ = ['main', 'server']

================
File: src/mcp_dev_server/docker/manager.py
================
import asyncio
import docker
from docker.errors import DockerException
from typing import Dict, List, Optional, Any
from pathlib import Path

from ..utils.logging import setup_logging
from ..utils.errors import DockerError
from .streams import EnhancedOutputStreamManager
from .streams import BiDirectionalSync

logger = setup_logging(__name__)

class DockerManager:
    def __init__(self):
        self.client = docker.from_env()
        self.containers = {}
        # Update to use enhanced versions
        self.output_manager = EnhancedOutputStreamManager(self)
        self.file_sync = BiDirectionalSync(self)
        
    async def create_container(
        self,
        project_path: str,
        environment: str,
        dockerfile: Optional[str] = None,
        ports: Optional[Dict[str, str]] = None,
        volumes: Optional[Dict[str, Dict[str, str]]] = None,
        environment_vars: Optional[Dict[str, str]] = None
    ) -> str:
        """Create and start a Docker container."""
        try:
            # Build image if Dockerfile provided
            if dockerfile:
                image, _ = self.client.images.build(
                    path=project_path,
                    dockerfile=dockerfile,
                    tag=f"mcp-dev-{environment}"
                )
            else:
                image = f"mcp-dev-{environment}"
            
            # Create container
            container = self.client.containers.run(
                image,
                name=f"mcp-dev-{environment}",
                detach=True,
                ports=ports or {},
                volumes=volumes or {},
                environment=environment_vars or {},
                remove=True  # Auto-remove when stopped
            )
            
            # Store container reference
            self.containers[environment] = container
            
            logger.info(f"Created container for environment: {environment}")
            return container.id
            
        except DockerException as e:
            raise DockerError(f"Failed to create container: {str(e)}")
            
    async def stop_container(self, environment: str) -> None:
        """Stop a running container."""
        try:
            if container := self.containers.get(environment):
                container.stop()
                del self.containers[environment]
                logger.info(f"Stopped container for environment: {environment}")
            
        except DockerException as e:
            raise DockerError(f"Failed to stop container: {str(e)}")
            
    async def execute_command(
        self,
        environment: str,
        command: str,
        workdir: Optional[str] = None
    ) -> Dict[str, Any]:
        """Execute a command in a container."""
        try:
            if container := self.containers.get(environment):
                exec_result = container.exec_run(
                    command,
                    workdir=workdir,
                    demux=True
                )
                
                return {
                    "exit_code": exec_result.exit_code,
                    "output": exec_result.output[0].decode() if exec_result.output[0] else "",
                    "error": exec_result.output[1].decode() if exec_result.output[1] else ""
                }
            else:
                raise DockerError(f"Container not found: {environment}")
                
        except DockerException as e:
            raise DockerError(f"Failed to execute command: {str(e)}")
            
    async def get_container_status(self, environment: str) -> Dict[str, Any]:
        """Get container status and stats."""
        try:
            if container := self.containers.get(environment):
                stats = container.stats(stream=False)
                return {
                    "id": container.id,
                    "status": container.status,
                    "state": container.attrs['State'],
                    "stats": {
                        "cpu_usage": stats['cpu_stats']['cpu_usage']['total_usage'],
                        "memory_usage": stats['memory_stats']['usage'],
                        "network_rx": stats['networks']['eth0']['rx_bytes'],
                        "network_tx": stats['networks']['eth0']['tx_bytes']
                    }
                }
            else:
                raise DockerError(f"Container not found: {environment}")
                
        except DockerException as e:
            raise DockerError(f"Failed to get container status: {str(e)}")
            
    async def cleanup(self) -> None:
        """Stop all containers and cleanup resources."""
        try:
            for environment, container in self.containers.items():
                try:
                    container.stop()
                    logger.info(f"Stopped container: {environment}")
                except Exception as e:
                    logger.error(f"Error stopping container {environment}: {str(e)}")
                    
            self.containers.clear()
            
        except Exception as e:
            logger.error(f"Error during Docker cleanup: {str(e)}")

================
File: src/mcp_dev_server/docker/streams.py
================
"""Container output streaming and file synchronization."""
import os
import time
import asyncio
import hashlib
import collections
from enum import Enum
from datetime import datetime
from typing import Dict, List, Optional, AsyncGenerator, Any
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from ..utils.logging import setup_logging
from ..utils.errors import StreamError, SyncError

logger = setup_logging(__name__)

class OutputFormat(str, Enum):
    """Output stream formats."""
    STDOUT = "stdout"
    STDERR = "stderr"
    COMBINED = "combined"
    FORMATTED = "formatted"

class StreamConfig:
    """Stream configuration."""
    def __init__(
        self,
        format: OutputFormat = OutputFormat.COMBINED,
        buffer_size: int = 1024,
        filters: Optional[List[str]] = None,
        timestamp: bool = False
    ):
        self.format = format
        self.buffer_size = buffer_size
        self.filters = filters or []
        self.timestamp = timestamp

class SyncConfig:
    """Synchronization configuration."""
    def __init__(
        self,
        ignore_patterns: Optional[List[str]] = None,
        sync_interval: float = 1.0,
        atomic: bool = True
    ):
        self.ignore_patterns = ignore_patterns or []
        self.sync_interval = sync_interval
        self.atomic = atomic

class StreamInfo:
    """Information about an active stream."""
    def __init__(self, task: asyncio.Task, config: StreamConfig):
        self.task = task
        self.config = config
        self.start_time = datetime.now()

class EnhancedOutputStreamManager:
    """Enhanced streaming output manager."""
    
    def __init__(self, docker_manager):
        self.docker_manager = docker_manager
        self.active_streams: Dict[str, StreamInfo] = {}
        self._buffer = collections.deque(maxlen=1000)  # Keep last 1000 messages
        
    async def start_stream(
        self,
        container_name: str,
        command: str,
        config: StreamConfig,
        callback: Optional[callable] = None
    ) -> AsyncGenerator[str, None]:
        """Start enhanced output stream."""
        try:
            container = self.docker_manager.containers.get(container_name)
            if not container:
                raise StreamError(f"Container not found: {container_name}")

            # Create execution with specified format
            exec_result = container.exec_run(
                command,
                stream=True,
                demux=True,
                socket=True  # Use socket for better streaming
            )

            async def stream_handler():
                buffer = []
                try:
                    async for data in exec_result.output:
                        # Apply format and filtering
                        processed_data = self._process_stream_data(data, config)
                        
                        if processed_data:
                            buffer.extend(processed_data)
                            if len(buffer) >= config.buffer_size:
                                output = ''.join(buffer)
                                buffer.clear()
                                
                                self._buffer.append(output)
                                
                                if callback:
                                    await callback(output)
                                yield output
                except Exception as e:
                    logger.error(f"Stream processing error: {str(e)}")
                    raise StreamError(f"Stream processing error: {str(e)}")
                finally:
                    if buffer:
                        output = ''.join(buffer)
                        self._buffer.append(output)
                        if callback:
                            await callback(output)
                        yield output

                    if container_name in self.active_streams:
                        del self.active_streams[container_name]

            # Create and store stream task
            stream_task = asyncio.create_task(stream_handler())
            self.active_streams[container_name] = StreamInfo(stream_task, config)
            
            async for output in stream_task:
                yield output

        except Exception as e:
            logger.error(f"Failed to start stream: {str(e)}")
            raise StreamError(f"Failed to start stream: {str(e)}")

    def _process_stream_data(
        self,
        data: bytes,
        config: StreamConfig
    ) -> Optional[str]:
        """Process stream data according to config."""
        if not data:
            return None
            
        # Split streams if demuxed
        stdout, stderr = data if isinstance(data, tuple) else (data, None)
        
        # Apply format
        if config.format == OutputFormat.STDOUT and stdout:
            output = stdout.decode()
        elif config.format == OutputFormat.STDERR and stderr:
            output = stderr.decode()
        elif config.format == OutputFormat.COMBINED:
            output = ''
            if stdout:
                output += stdout.decode()
            if stderr:
                output += stderr.decode()
        elif config.format == OutputFormat.FORMATTED:
            output = self._format_output(stdout, stderr)
        else:
            return None
            
        # Apply filters
        for filter_pattern in config.filters:
            if filter_pattern in output:
                return None
                
        # Add timestamp if requested
        if config.timestamp:
            output = f"[{datetime.now().isoformat()}] {output}"
            
        return output
        
    @staticmethod
    def _format_output(stdout: Optional[bytes], stderr: Optional[bytes]) -> str:
        """Format output with colors and prefixes."""
        output = []
        
        if stdout:
            output.append(f"\033[32m[OUT]\033[0m {stdout.decode()}")
        if stderr:
            output.append(f"\033[31m[ERR]\033[0m {stderr.decode()}")
            
        return '\n'.join(output)

    async def stop_stream(self, container_name: str) -> None:
        """Stop streaming from a container."""
        if stream_info := self.active_streams.get(container_name):
            stream_info.task.cancel()
            try:
                await stream_info.task
            except asyncio.CancelledError:
                pass
            del self.active_streams[container_name]

class BiDirectionalSync:
    """Enhanced bi-directional file synchronization."""
    
    def __init__(self, docker_manager):
        self.docker_manager = docker_manager
        self.sync_handlers: Dict[str, EnhancedSyncHandler] = {}
        self.observer = Observer()
        self.observer.start()
        
    async def start_sync(
        self,
        container_name: str,
        host_path: str,
        container_path: str,
        config: SyncConfig
    ) -> None:
        """Start bi-directional file sync."""
        try:
            # Validate paths
            if not os.path.exists(host_path):
                raise SyncError(f"Host path does not exist: {host_path}")
            
            container = self.docker_manager.containers.get(container_name)
            if not container:
                raise SyncError(f"Container not found: {container_name}")
            
            # Create sync handler
            handler = EnhancedSyncHandler(
                container=container,
                container_path=container_path,
                host_path=host_path,
                config=config
            )
            
            # Start watching both directions
            self.observer.schedule(
                handler,
                host_path,
                recursive=True
            )
            
            # Start container file watcher
            await handler.start_container_watcher()
            
            self.sync_handlers[container_name] = handler
            logger.info(f"Started bi-directional sync for container: {container_name}")
            
        except Exception as e:
            raise SyncError(f"Failed to start sync: {str(e)}")

    async def stop_sync(self, container_name: str) -> None:
        """Stop synchronization for a container."""
        if handler := self.sync_handlers.get(container_name):
            self.observer.unschedule_all()
            await handler.stop_container_watcher()
            del self.sync_handlers[container_name]
            logger.info(f"Stopped sync for container: {container_name}")

    async def cleanup(self) -> None:
        """Clean up all synchronization handlers."""
        for container_name in list(self.sync_handlers.keys()):
            await self.stop_sync(container_name)
        self.observer.stop()
        self.observer.join()

class EnhancedSyncHandler(FileSystemEventHandler):
    """Enhanced sync handler with bi-directional support."""
    
    def __init__(
        self,
        container,
        container_path: str,
        host_path: str,
        config: SyncConfig
    ):
        super().__init__()
        self.container = container
        self.container_path = container_path
        self.host_path = host_path
        self.config = config
        self.sync_lock = asyncio.Lock()
        self.pending_syncs: Dict[str, float] = {}
        self._container_watcher: Optional[asyncio.Task] = None
        
    async def start_container_watcher(self) -> None:
        """Start watching container files."""
        cmd = f"""
        inotifywait -m -r -e modify,create,delete,move {self.container_path}
        """
        
        exec_result = self.container.exec_run(
            cmd,
            stream=True,
            detach=True
        )
        
        self._container_watcher = asyncio.create_task(
            self._handle_container_events(exec_result.output)
        )
        
    async def stop_container_watcher(self) -> None:
        """Stop container file watcher."""
        if self._container_watcher:
            self._container_watcher.cancel()
            try:
                await self._container_watcher
            except asyncio.CancelledError:
                pass
            self._container_watcher = None
        
    async def _handle_container_events(self, output_stream: AsyncGenerator) -> None:
        """Handle container file events."""
        try:
            async for event in output_stream:
                await self._handle_container_change(event.decode())
        except Exception as e:
            logger.error(f"Container watcher error: {str(e)}")
            
    async def _handle_container_change(self, event: str) -> None:
        """Handle container file change."""
        try:
            # Parse inotify event
            parts = event.strip().split()
            if len(parts) >= 3:
                path = parts[0]
                change_type = parts[1]
                filename = parts[2]
                
                container_path = os.path.join(path, filename)
                host_path = self._container_to_host_path(container_path)
                
                # Apply filters
                if self._should_ignore(host_path):
                    return
                    
                async with self.sync_lock:
                    # Check if change is from host sync
                    if host_path in self.pending_syncs:
                        if time.time() - self.pending_syncs[host_path] < self.config.sync_interval:
                            return
                            
                    # Sync from container to host
                    await self._sync_to_host(container_path, host_path)
                    
        except Exception as e:
            logger.error(f"Error handling container change: {str(e)}")
            
    def _container_to_host_path(self, container_path: str) -> str:
        """Convert container path to host path."""
        rel_path = os.path.relpath(container_path, self.container_path)
        return os.path.join(self.host_path, rel_path)

    def _should_ignore(self, path: str) -> bool:
        """Check if path should be ignored."""
        return any(pattern in path for pattern in self.config.ignore_patterns)
        
    async def _sync_to_host(
        self,
        container_path: str,
        host_path: str
    ) -> None:
        """Sync file from container to host."""
        try:
            # Get file from container
            stream, stat = self.container.get_archive(container_path)
            
            # Create parent directories
            os.makedirs(os.path.dirname(host_path), exist_ok=True)
            
            if self.config.atomic:
                # Save file atomically using temporary file
                tmp_path = f"{host_path}.tmp"
                with open(tmp_path, 'wb') as f:
                    for chunk in stream:
                        f.write(chunk)
                os.rename(tmp_path, host_path)
            else:
                # Direct write
                with open(host_path, 'wb') as f:
                    for chunk in stream:
                        f.write(chunk)
            
            # Update sync tracking
            self.pending_syncs[host_path] = time.time()
            
        except Exception as e:
            logger.error(f"Error syncing to host: {str(e)}")
            raise SyncError(f"Failed to sync file {container_path}: {str(e)}")

================
File: src/mcp_dev_server/docker/templates.py
================
"""Dockerfile templates for different environments."""
from typing import Dict, Optional
from jinja2 import Template

class DockerTemplates:
    """Manages Dockerfile templates for different environments."""
    
    @staticmethod
    def get_template(environment: str, config: Optional[Dict[str, Any]] = None) -> str:
        """Get Dockerfile template for specific environment."""
        config = config or {}
        
        if environment == "python":
            return Template("""
FROM python:{{ python_version|default('3.12-slim') }}

WORKDIR /app

{% if requirements_file %}
COPY {{ requirements_file }} .
RUN pip install -r {{ requirements_file }}
{% endif %}

{% if install_dev_deps %}
RUN pip install pytest mypy black
{% endif %}

{% for cmd in additional_commands|default([]) %}
RUN {{ cmd }}
{% endfor %}

COPY . .

CMD ["python", "{{ entry_point|default('main.py') }}"]
""").render(config)
            
        elif environment == "node":
            return Template("""
FROM node:{{ node_version|default('20-slim') }}

WORKDIR /app

COPY package*.json ./

RUN npm install {% if install_dev_deps %}--include=dev{% endif %}

{% for cmd in additional_commands|default([]) %}
RUN {{ cmd }}
{% endfor %}

COPY . .

CMD ["npm", "{{ npm_command|default('start') }}"]
""").render(config)
            
        else:
            raise ValueError(f"Unknown environment: {environment}")

================
File: src/mcp_dev_server/docker/volumes.py
================
"""Docker volume management for MCP Development Server."""
from typing import Dict, List, Optional
import docker
from docker.errors import DockerException

from ..utils.logging import setup_logging
from ..utils.errors import DockerError

logger = setup_logging(__name__)

class VolumeManager:
    """Manages Docker volumes for development environments."""
    
    def __init__(self):
        self.client = docker.from_env()
        
    async def create_volume(
        self,
        name: str,
        labels: Optional[Dict[str, str]] = None
    ) -> str:
        """Create a Docker volume."""
        try:
            volume = self.client.volumes.create(
                name=name,
                driver='local',
                labels=labels or {}
            )
            logger.info(f"Created volume: {name}")
            return volume.name
            
        except DockerException as e:
            raise DockerError(f"Failed to create volume: {str(e)}")
            
    async def remove_volume(self, name: str) -> None:
        """Remove a Docker volume."""
        try:
            volume = self.client.volumes.get(name)
            volume.remove()
            logger.info(f"Removed volume: {name}")
            
        except DockerException as e:
            raise DockerError(f"Failed to remove volume: {str(e)}")
            
    async def list_volumes(
        self,
        filters: Optional[Dict[str, str]] = None
    ) -> List[Dict[str, Any]]:
        """List Docker volumes."""
        try:
            volumes = self.client.volumes.list(filters=filters or {})
            return [
                {
                    "name": v.name,
                    "driver": v.attrs['Driver'],
                    "mountpoint": v.attrs['Mountpoint'],
                    "labels": v.attrs['Labels'] or {}
                }
                for v in volumes
            ]
            
        except DockerException as e:
            raise DockerError(f"Failed to list volumes: {str(e)}")
            
    async def get_volume_info(self, name: str) -> Dict[str, Any]:
        """Get detailed information about a volume."""
        try:
            volume = self.client.volumes.get(name)
            return {
                "name": volume.name,
                "driver": volume.attrs['Driver'],
                "mountpoint": volume.attrs['Mountpoint'],
                "labels": volume.attrs['Labels'] or {},
                "scope": volume.attrs['Scope'],
                "status": volume.attrs.get('Status', {})
            }
            
        except DockerException as e:
            raise DockerError(f"Failed to get volume info: {str(e)}")

================
File: src/mcp_dev_server/environments/manager.py
================
"""Environment management for MCP Development Server."""
import os
import json
from typing import Dict, List, Optional, Any
from pathlib import Path

from ..docker.manager import DockerManager
from ..docker.volumes import VolumeManager
from ..docker.templates import DockerTemplates
from ..utils.logging import setup_logging
from ..utils.errors import EnvironmentError

logger = setup_logging(__name__)

class EnvironmentManager:
    """Manages development environments."""
    
    def __init__(self):
        self.docker_manager = DockerManager()
        self.volume_manager = VolumeManager()
        self.environments: Dict[str, Dict[str, Any]] = {}
        
    async def create_environment(
        self,
        name: str,
        project_path: str,
        env_type: str,
        config: Optional[Dict[str, Any]] = None
    ) -> str:
        """Create a new development environment."""
        try:
            config = config or {}
            
            # Create environment directory
            env_path = os.path.join(project_path, '.mcp', 'environments', name)
            os.makedirs(env_path, exist_ok=True)
            
            # Generate Dockerfile
            dockerfile_content = DockerTemplates.get_template(env_type, config)
            dockerfile_path = os.path.join(env_path, 'Dockerfile')
            with open(dockerfile_path, 'w') as f:
                f.write(dockerfile_content)
            
            # Create volumes for persistence
            volumes = {}
            for volume_name in ['src', 'deps', 'cache']:
                volume = await self.volume_manager.create_volume(
                    f"mcp-{name}-{volume_name}",
                    labels={
                        'mcp.environment': name,
                        'mcp.volume.type': volume_name
                    }
                )
                volumes[volume] = {'bind': f'/app/{volume_name}', 'mode': 'rw'}
            
            # Create container
            container_id = await self.docker_manager.create_container(
                project_path=project_path,
                environment=name,
                dockerfile=dockerfile_path,
                volumes=volumes,
                environment_vars=config.get('env_vars'),
                ports=config.get('ports')
            )
            
            # Store environment configuration
            self.environments[name] = {
                'id': container_id,
                'type': env_type,
                'path': env_path,
                'config': config,
                'volumes': volumes
            }
            
            # Save environment metadata
            self._save_environment_metadata(name)
            
            logger.info(f"Created environment: {name}")
            return container_id
            
        except Exception as e:
            raise EnvironmentError(f"Failed to create environment: {str(e)}")
            
    async def remove_environment(self, name: str) -> None:
        """Remove a development environment."""
        try:
            if env := self.environments.get(name):
                # Stop container
                await self.docker_manager.stop_container(name)
                
                # Remove volumes
                for volume in env['volumes']:
                    await self.volume_manager.remove_volume(volume)
                
                # Remove environment directory
                import shutil
                shutil.rmtree(env['path'])
                
                # Remove from environments dict
                del self.environments[name]
                
                logger.info(f"Removed environment: {name}")
            else:
                raise EnvironmentError(f"Environment not found: {name}")
                
        except Exception as e:
            raise EnvironmentError(f"Failed to remove environment: {str(e)}")
            
    async def execute_in_environment(
        self,
        name: str,
        command: str,
        workdir: Optional[str] = None
    ) -> Dict[str, Any]:
        """Execute a command in an environment."""
        try:
            if name not in self.environments:
                raise EnvironmentError(f"Environment not found: {name}")
                
            return await self.docker_manager.execute_command(
                environment=name,
                command=command,
                workdir=workdir
            )
            
        except Exception as e:
            raise EnvironmentError(f"Failed to execute command: {str(e)}")
            
    async def get_environment_status(self, name: str) -> Dict[str, Any]:
        """Get environment status including container and volumes."""
        try:
            if env := self.environments.get(name):
                container_status = await self.docker_manager.get_container_status(name)
                
                volumes_status = {}
                for volume in env['volumes']:
                    volumes_status[volume] = await self.volume_manager.get_volume_info(volume)
                
                return {
                    'container': container_status,
                    'volumes': volumes_status,
                    'type': env['type'],
                    'config': env['config']
                }
            else:
                raise EnvironmentError(f"Environment not found: {name}")
                
        except Exception as e:
            raise EnvironmentError(f"Failed to get environment status: {str(e)}")
            
    def _save_environment_metadata(self, name: str) -> None:
        """Save environment metadata to disk."""
        if env := self.environments.get(name):
            metadata_path = os.path.join(env['path'], 'metadata.json')
            with open(metadata_path, 'w') as f:
                json.dump({
                    'name': name,
                    'type': env['type'],
                    'config': env['config'],
                    'volumes': list(env['volumes'].keys())
                }, f, indent=2)
                
    async def cleanup(self) -> None:
        """Clean up all environments."""
        for name in list(self.environments.keys()):
            try:
                await self.remove_environment(name)
            except Exception as e:
                logger.error(f"Error cleaning up environment {name}: {str(e)}")

================
File: src/mcp_dev_server/environments/tools.py
================
"""Development tools integration for environments."""
import shutil
import subprocess
from typing import Dict, Optional, Any
from pathlib import Path

from ..utils.logging import setup_logging
from ..utils.errors import ToolError

logger = setup_logging(__name__)

class ToolManager:
    """Manages development tools in environments."""
    
    def __init__(self, env_manager):
        self.env_manager = env_manager
        
    async def setup_package_manager(
        self,
        environment: str,
        package_manager: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Set up package manager in an environment."""
        try:
            config = config or {}
            
            if package_manager == "npm":
                return await self._setup_npm(environment, config)
            elif package_manager == "pip":
                return await self._setup_pip(environment, config)
            else:
                raise ToolError(f"Unsupported package manager: {package_manager}")
                
        except Exception as e:
            raise ToolError(f"Failed to setup package manager: {str(e)}")
            
    async def setup_build_tool(
        self,
        environment: str,
        build_tool: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Set up build tool in an environment."""
        try:
            config = config or {}
            
            if build_tool == "webpack":
                return await self._setup_webpack(environment, config)
            elif build_tool == "vite":
                return await self._setup_vite(environment, config)
            else:
                raise ToolError(f"Unsupported build tool: {build_tool}")
                
        except Exception as e:
            raise ToolError(f"Failed to setup build tool: {str(e)}")
            
    async def setup_test_framework(
        self,
        environment: str,
        test_framework: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Set up testing framework in an environment."""
        try:
            config = config or {}
            
            if test_framework == "jest":
                return await self._setup_jest(environment, config)
            elif test_framework == "pytest":
                return await self._setup_pytest(environment, config)
            else:
                raise ToolError(f"Unsupported test framework: {test_framework}")
                
        except Exception as e:
            raise ToolError(f"Failed to setup test framework: {str(e)}")
            
    async def _setup_npm(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up NPM package manager."""
        try:
            # Initialize package.json if needed
            if not config.get('skip_init'):
                result = await self.env_manager.execute_in_environment(
                    environment,
                    'npm init -y'
                )
                if result['exit_code'] != 0:
                    raise ToolError(f"npm init failed: {result['error']}")
            
            # Install dependencies if specified
            if deps := config.get('dependencies'):
                deps_str = ' '.join(deps)
                result = await self.env_manager.execute_in_environment(
                    environment,
                    f'npm install {deps_str}'
                )
                if result['exit_code'] != 0:
                    raise ToolError(f"npm install failed: {result['error']}")
                    
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"NPM setup failed: {str(e)}")
            
    async def _setup_pip(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up Pip package manager."""
        try:
            # Create virtual environment if needed
            if not config.get('skip_venv'):
                result = await self.env_manager.execute_in_environment(
                    environment,
                    'python -m venv .venv'
                )
                if result['exit_code'] != 0:
                    raise ToolError(f"venv creation failed: {result['error']}")
            
            # Install dependencies if specified
            if deps := config.get('dependencies'):
                deps_str = ' '.join(deps)
                result = await self.env_manager.execute_in_environment(
                    environment,
                    f'pip install {deps_str}'
                )
                if result['exit_code'] != 0:
                    raise ToolError(f"pip install failed: {result['error']}")
                    
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"Pip setup failed: {str(e)}")
            
    async def _setup_webpack(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up Webpack build tool."""
        try:
            # Install webpack and dependencies
            result = await self.env_manager.execute_in_environment(
                environment,
                'npm install webpack webpack-cli --save-dev'
            )
            if result['exit_code'] != 0:
                raise ToolError(f"webpack installation failed: {result['error']}")
                
            # Create webpack config if not exists
            config_content = """
            const path = require('path');
            
            module.exports = {
              entry: './src/index.js',
              output: {
                path: path.resolve(__dirname, 'dist'),
                filename: 'bundle.js'
              }
            };
            """
            
            config_path = Path(self.env_manager.environments[environment]['path']) / 'webpack.config.js'
            config_path.write_text(config_content)
            
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"Webpack setup failed: {str(e)}")
            
    async def _setup_vite(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up Vite build tool."""
        try:
            # Install vite
            result = await self.env_manager.execute_in_environment(
                environment,
                'npm install vite --save-dev'
            )
            if result['exit_code'] != 0:
                raise ToolError(f"vite installation failed: {result['error']}")
                
            # Create vite config if not exists
            config_content = """
            export default {
              root: 'src',
              build: {
                outDir: '../dist'
              }
            }
            """
            
            config_path = Path(self.env_manager.environments[environment]['path']) / 'vite.config.js'
            config_path.write_text(config_content)
            
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"Vite setup failed: {str(e)}")
            
    async def _setup_jest(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up Jest testing framework."""
        try:
            # Install jest and dependencies
            result = await self.env_manager.execute_in_environment(
                environment,
                'npm install jest @types/jest --save-dev'
            )
            if result['exit_code'] != 0:
                raise ToolError(f"jest installation failed: {result['error']}")
                
            # Create jest config if not exists
            config_content = """
            module.exports = {
              testEnvironment: 'node',
              testMatch: ['**/*.test.js'],
              collectCoverage: true
            };
            """
            
            config_path = Path(self.env_manager.environments[environment]['path']) / 'jest.config.js'
            config_path.write_text(config_content)
            
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"Jest setup failed: {str(e)}")
            
    async def _setup_pytest(self, environment: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """Set up Pytest testing framework."""
        try:
            # Install pytest and dependencies
            result = await self.env_manager.execute_in_environment(
                environment,
                'pip install pytest pytest-cov'
            )
            if result['exit_code'] != 0:
                raise ToolError(f"pytest installation failed: {result['error']}")
                
            # Create pytest config if not exists
            config_content = """
            [pytest]
            testpaths = tests
            python_files = test_*.py
            addopts = --cov=src
            """
            
            config_path = Path(self.env_manager.environments[environment]['path']) / 'pytest.ini'
            config_path.write_text(config_content)
            
            return {"status": "success"}
            
        except Exception as e:
            raise ToolError(f"Pytest setup failed: {str(e)}")

================
File: src/mcp_dev_server/environments/workflow.py
================
"""Development workflow management for environments."""
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
import asyncio

from ..utils.logging import setup_logging
from ..utils.errors import WorkflowError

logger = setup_logging(__name__)

class TaskStatus(str, Enum):
    """Workflow task status."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class Task:
    """Represents a workflow task."""
    
    def __init__(
        self,
        name: str,
        command: str,
        environment: str,
        dependencies: Optional[List[str]] = None,
        timeout: Optional[int] = None,
        retry_count: int = 0,
        on_success: Optional[Callable] = None,
        on_failure: Optional[Callable] = None
    ):
        self.name = name
        self.command = command
        self.environment = environment
        self.dependencies = dependencies or []
        self.timeout = timeout
        self.retry_count = retry_count
        self.status = TaskStatus.PENDING
        self.result: Optional[Dict[str, Any]] = None
        self.on_success = on_success
        self.on_failure = on_failure
        self.attempts = 0

class Workflow:
    """Manages development workflows."""
    
    def __init__(self, env_manager):
        self.env_manager = env_manager
        self.tasks: Dict[str, Task] = {}
        self.running = False
        
    def add_task(self, task: Task) -> None:
        """Add a task to the workflow."""
        self.tasks[task.name] = task
        
    def remove_task(self, task_name: str) -> None:
        """Remove a task from the workflow."""
        if task_name in self.tasks:
            del self.tasks[task_name]
            
    async def execute(self) -> Dict[str, Any]:
        """Execute the workflow."""
        try:
            self.running = True
            results = {}
            
            # Build dependency graph
            graph = self._build_dependency_graph()
            
            # Execute tasks in order
            for task_group in graph:
                # Execute tasks in group concurrently
                tasks = [self._execute_task(task_name) for task_name in task_group]
                group_results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # Process results
                for task_name, result in zip(task_group, group_results):
                    if isinstance(result, Exception):
                        self.tasks[task_name].status = TaskStatus.FAILED
                        results[task_name] = {
                            "status": TaskStatus.FAILED,
                            "error": str(result)
                        }
                    else:
                        results[task_name] = result
                
            return results
            
        except Exception as e:
            raise WorkflowError(f"Workflow execution failed: {str(e)}")
        finally:
            self.running = False
            
    async def _execute_task(self, task_name: str) -> Dict[str, Any]:
        """Execute a single task."""
        task = self.tasks[task_name]
        
        # Check dependencies
        for dep in task.dependencies:
            dep_task = self.tasks.get(dep)
            if not dep_task or dep_task.status != TaskStatus.COMPLETED:
                task.status = TaskStatus.SKIPPED
                return {
                    "status": TaskStatus.SKIPPED,
                    "reason": f"Dependency {dep} not satisfied"
                }
        
        task.status = TaskStatus.RUNNING
        task.attempts += 1
        
        try:
            # Execute the command
            result = await asyncio.wait_for(
                self.env_manager.execute_in_environment(
                    task.environment,
                    task.command
                ),
                timeout=task.timeout
            )
            
            # Handle execution result
            if result['exit_code'] == 0:
                task.status = TaskStatus.COMPLETED
                if task.on_success:
                    await task.on_success(result)
                return {
                    "status": TaskStatus.COMPLETED,
                    "result": result
                }
            else:
                # Handle retry logic
                if task.attempts < task.retry_count + 1:
                    logger.info(f"Retrying task {task_name} (attempt {task.attempts})")
                    return await self._execute_task(task_name)
                
                task.status = TaskStatus.FAILED
                if task.on_failure:
                    await task.on_failure(result)
                return {
                    "status": TaskStatus.FAILED,
                    "result": result
                }
                
        except asyncio.TimeoutError:
            task.status = TaskStatus.FAILED
            return {
                "status": TaskStatus.FAILED,
                "error": "Task timeout"
            }
            
        except Exception as e:
            task.status = TaskStatus.FAILED
            return {
                "status": TaskStatus.FAILED,
                "error": str(e)
            }
            
    def _build_dependency_graph(self) -> List[List[str]]:
        """Build ordered list of task groups based on dependencies."""
        # Initialize variables
        graph: List[List[str]] = []
        completed = set()
        remaining = set(self.tasks.keys())
        
        while remaining:
            # Find tasks with satisfied dependencies
            group = set()
            for task_name in remaining:
                task = self.tasks[task_name]
                if all(dep in completed for dep in task.dependencies):
                    group.add(task_name)
            
            if not group:
                # Circular dependency detected
                raise WorkflowError("Circular dependency detected in workflow")
            
            # Add group to graph
            graph.append(list(group))
            completed.update(group)
            remaining.difference_update(group)
            
        return graph
        
    def get_status(self) -> Dict[str, Any]:
        """Get workflow status."""
        return {
            "running": self.running,
            "tasks": {
                name: {
                    "status": task.status,
                    "attempts": task.attempts,
                    "dependencies": task.dependencies
                }
                for name, task in self.tasks.items()
            }
        }
        
    def reset(self) -> None:
        """Reset workflow state."""
        for task in self.tasks.values():
            task.status = TaskStatus.PENDING
            task.attempts = 0
            task.result = None
        self.running = False

# Example workflow definitions for common development tasks
class CommonWorkflows:
    """Predefined development workflows."""
    
    @staticmethod
    def create_build_workflow(env_manager, environment: str) -> Workflow:
        """Create a standard build workflow."""
        workflow = Workflow(env_manager)
        
        # Install dependencies
        workflow.add_task(Task(
            name="install_deps",
            command="npm install",
            environment=environment,
            retry_count=2
        ))
        
        # Run linter
        workflow.add_task(Task(
            name="lint",
            command="npm run lint",
            environment=environment,
            dependencies=["install_deps"]
        ))
        
        # Run tests
        workflow.add_task(Task(
            name="test",
            command="npm run test",
            environment=environment,
            dependencies=["install_deps"]
        ))
        
        # Build
        workflow.add_task(Task(
            name="build",
            command="npm run build",
            environment=environment,
            dependencies=["lint", "test"]
        ))
        
        return workflow
        
    @staticmethod
    def create_test_workflow(env_manager, environment: str) -> Workflow:
        """Create a standard test workflow."""
        workflow = Workflow(env_manager)
        
        # Install test dependencies
        workflow.add_task(Task(
            name="install_test_deps",
            command="npm install --only=dev",
            environment=environment,
            retry_count=2
        ))
        
        # Run unit tests
        workflow.add_task(Task(
            name="unit_tests",
            command="npm run test:unit",
            environment=environment,
            dependencies=["install_test_deps"]
        ))
        
        # Run integration tests
        workflow.add_task(Task(
            name="integration_tests",
            command="npm run test:integration",
            environment=environment,
            dependencies=["install_test_deps"]
        ))
        
        # Generate coverage report
        workflow.add_task(Task(
            name="coverage",
            command="npm run coverage",
            environment=environment,
            dependencies=["unit_tests", "integration_tests"]
        ))
        
        return workflow

================
File: src/mcp_dev_server/project_manager/context.py
================
"""Project context management for MCP Development Server."""
import os
import json
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from pydantic import BaseModel
from ..utils.config import ProjectConfig
from ..utils.logging import setup_logging
from ..utils.errors import ProjectError, FileOperationError

logger = setup_logging(__name__)

class ProjectState(BaseModel):
    """Project state tracking."""
    initialized: bool = False
    last_build_time: Optional[datetime] = None
    last_build_status: Optional[str] = None
    last_test_time: Optional[datetime] = None
    last_test_status: Optional[str] = None
    git_initialized: bool = False

class ProjectContext:
    """Manages the context and state of a development project."""
    
    def __init__(self, config: ProjectConfig):
        self.id = str(uuid.uuid4())
        self.config = config
        self.path = config.path
        self.state = ProjectState()
        self._file_watchers: Dict[str, Any] = {}
        
    async def initialize(self) -> None:
        """Initialize project structure and state."""
        try:
            # Create project directory
            os.makedirs(self.path, exist_ok=True)
            
            # Create project structure
            await self._create_project_structure()
            
            # Initialize state file
            await self._init_state_file()
            
            # Set up file watchers
            await self._setup_file_watchers()
            
            self.state.initialized = True
            logger.info(f"Initialized project {self.config.name} at {self.path}")
            
        except Exception as e:
            raise ProjectError(f"Project initialization failed: {str(e)}")
            
    async def _create_project_structure(self) -> None:
        """Create initial project directory structure."""
        try:
            # Create standard directories
            for dir_name in ['.mcp', 'src', 'tests', 'docs']:
                os.makedirs(os.path.join(self.path, dir_name), exist_ok=True)
                
            # Create basic configuration files
            config_path = os.path.join(self.path, '.mcp', 'project.json')
            with open(config_path, 'w') as f:
                json.dump(self.config.dict(), f, indent=2, default=str)
                
        except Exception as e:
            raise FileOperationError(f"Failed to create project structure: {str(e)}")
            
    async def _init_state_file(self) -> None:
        """Initialize project state file."""
        try:
            state_path = os.path.join(self.path, '.mcp', 'state.json')
            with open(state_path, 'w') as f:
                json.dump(self.state.dict(), f, indent=2, default=str)
                
        except Exception as e:
            raise FileOperationError(f"Failed to initialize state file: {str(e)}")
            
    async def _setup_file_watchers(self) -> None:
        """Set up file system watchers for project directories."""
        # To be implemented with file watching functionality
        pass
        
    def get_structure(self) -> Dict[str, Any]:
        """Get project structure as a dictionary."""
        structure = {"name": self.config.name, "type": "directory", "children": []}
        
        def scan_directory(path: Path, current_dict: Dict[str, Any]) -> None:
            try:
                for item in path.iterdir():
                    # Skip hidden files and .mcp directory
                    if item.name.startswith('.'):
                        continue
                        
                    if item.is_file():
                        current_dict["children"].append({
                            "name": item.name,
                            "type": "file",
                            "size": item.stat().st_size
                        })
                    elif item.is_dir():
                        dir_dict = {
                            "name": item.name,
                            "type": "directory",
                            "children": []
                        }
                        current_dict["children"].append(dir_dict)
                        scan_directory(item, dir_dict)
                        
            except Exception as e:
                logger.error(f"Error scanning directory {path}: {str(e)}")
                
        scan_directory(Path(self.path), structure)
        return structure
        
    def get_file_content(self, relative_path: str) -> str:
        """Get content of a project file."""
        try:
            file_path = os.path.join(self.path, relative_path)
            if not os.path.exists(file_path):
                raise FileOperationError(f"File not found: {relative_path}")
                
            # Basic security check
            if not os.path.normpath(file_path).startswith(str(self.path)):
                raise FileOperationError("Invalid file path")
                
            with open(file_path, 'r') as f:
                return f.read()
                
        except Exception as e:
            raise FileOperationError(f"Failed to read file {relative_path}: {str(e)}")
            
    async def update_file(self, relative_path: str, content: str) -> None:
        """Update content of a project file."""
        try:
            file_path = os.path.join(self.path, relative_path)
            
            # Create directories if needed
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # Security check
            if not os.path.normpath(file_path).startswith(str(self.path)):
                raise FileOperationError("Invalid file path")
                
            with open(file_path, 'w') as f:
                f.write(content)
                
            logger.info(f"Updated file: {relative_path}")
            
        except Exception as e:
            raise FileOperationError(f"Failed to update file {relative_path}: {str(e)}")
            
    async def delete_file(self, relative_path: str) -> None:
        """Delete a project file."""
        try:
            file_path = os.path.join(self.path, relative_path)
            
            # Security check
            if not os.path.normpath(file_path).startswith(str(self.path)):
                raise FileOperationError("Invalid file path")
                
            if os.path.exists(file_path):
                os.remove(file_path)
                logger.info(f"Deleted file: {relative_path}")
            else:
                logger.warning(f"File not found: {relative_path}")
                
        except Exception as e:
            raise FileOperationError(f"Failed to delete file {relative_path}: {str(e)}")
            
    async def update_state(self, **kwargs) -> None:
        """Update project state."""
        try:
            # Update state object
            for key, value in kwargs.items():
                if hasattr(self.state, key):
                    setattr(self.state, key, value)
                    
            # Save to state file
            state_path = os.path.join(self.path, '.mcp', 'state.json')
            with open(state_path, 'w') as f:
                json.dump(self.state.dict(), f, indent=2, default=str)
                
            logger.info(f"Updated project state: {kwargs}")
            
        except Exception as e:
            raise ProjectError(f"Failed to update project state: {str(e)}")
            
    async def cleanup(self) -> None:
        """Clean up project resources."""
        try:
            # Stop file watchers
            for watcher in self._file_watchers.values():
                await watcher.stop()
                
            logger.info(f"Cleaned up project resources for {self.config.name}")
            
        except Exception as e:
            logger.error(f"Error during project cleanup: {str(e)}")

================
File: src/mcp_dev_server/project_manager/git.py
================
"""Git integration for MCP Development Server."""
import os
from typing import List, Optional
from git import Repo, GitCommandError
from git.objects import Commit

from ..utils.logging import setup_logging
from ..utils.errors import GitError

logger = setup_logging(__name__)

class GitManager:
    """Manages Git operations for a project."""
    
    def __init__(self, project_path: str):
        self.project_path = project_path
        self.repo: Optional[Repo] = None
        
    async def initialize(self) -> None:
        """Initialize Git repository."""
        try:
            self.repo = Repo.init(self.project_path)
            
            # Create default .gitignore if it doesn't exist
            gitignore_path = os.path.join(self.project_path, '.gitignore')
            if not os.path.exists(gitignore_path):
                with open(gitignore_path, 'w') as f:
                    f.write('\n'.join([
                        '# Python',
                        '__pycache__/',
                        '*.pyc',
                        '*.pyo',
                        '*.pyd',
                        '.Python',
                        'env/',
                        'venv/',
                        '.env',
                        '.venv',
                        '',
                        '# IDE',
                        '.idea/',
                        '.vscode/',
                        '*.swp',
                        '*.swo',
                        '',
                        '# Project specific',
                        '.mcp/',
                        'dist/',
                        'build/',
                        '*.egg-info/',
                        ''
                    ]))
                
            # Initial commit
            if not self.repo.heads:
                self.repo.index.add(['.gitignore'])
                self.repo.index.commit("Initial commit")
                
            logger.info(f"Initialized Git repository at {self.project_path}")
            
        except Exception as e:
            raise GitError(f"Git initialization failed: {str(e)}")
            
    async def get_status(self) -> dict:
        """Get repository status."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            return {
                "branch": self.repo.active_branch.name,
                "changed_files": [item.a_path for item in self.repo.index.diff(None)],
                "untracked_files": self.repo.untracked_files,
                "is_dirty": self.repo.is_dirty(),
                "head_commit": {
                    "hash": self.repo.head.commit.hexsha,
                    "message": self.repo.head.commit.message,
                    "author": str(self.repo.head.commit.author),
                    "date": str(self.repo.head.commit.authored_datetime)
                }
            }
            
        except Exception as e:
            raise GitError(f"Failed to get Git status: {str(e)}")
            
    async def commit(self, message: str, files: Optional[List[str]] = None) -> str:
        """Create a new commit."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            # Add specified files or all changes
            if files:
                self.repo.index.add(files)
            else:
                self.repo.index.add('.')
                
            # Create commit
            commit = self.repo.index.commit(message)
            logger.info(f"Created commit: {commit.hexsha}")
            
            return commit.hexsha
            
        except Exception as e:
            raise GitError(f"Failed to create commit: {str(e)}")
            
    async def get_commit_history(
        self,
        max_count: Optional[int] = None
    ) -> List[dict]:
        """Get commit history."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            commits = []
            for commit in self.repo.iter_commits(max_count=max_count):
                commits.append({
                    "hash": commit.hexsha,
                    "message": commit.message,
                    "author": str(commit.author),
                    "date": str(commit.authored_datetime),
                    "files": list(commit.stats.files.keys())
                })
                
            return commits
            
        except Exception as e:
            raise GitError(f"Failed to get commit history: {str(e)}")
            
    async def create_branch(self, name: str) -> None:
        """Create a new branch."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            self.repo.create_head(name)
            logger.info(f"Created branch: {name}")
            
        except Exception as e:
            raise GitError(f"Failed to create branch: {str(e)}")
            
    async def checkout(self, branch: str) -> None:
        """Checkout a branch."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            self.repo.git.checkout(branch)
            logger.info(f"Checked out branch: {branch}")
            
        except Exception as e:
            raise GitError(f"Failed to checkout branch: {str(e)}")
            
    async def get_diff(
        self,
        commit_a: Optional[str] = None,
        commit_b: Optional[str] = None
    ) -> str:
        """Get diff between commits or working directory."""
        try:
            if not self.repo:
                raise GitError("Git repository not initialized")
                
            return self.repo.git.diff(commit_a, commit_b)
            
        except Exception as e:
            raise GitError(f"Failed to get diff: {str(e)}")
            
    async def cleanup(self) -> None:
        """Clean up Git resources."""
        self.repo = None

================
File: src/mcp_dev_server/project_manager/manager.py
================
"""Project management for MCP Development Server."""
import os
from typing import Dict, List, Optional
from pathlib import Path

from ..utils.config import ProjectConfig, Config
from ..utils.logging import setup_logging
from ..utils.errors import ProjectError, ProjectNotFoundError
from .context import ProjectContext
from .git import GitManager

logger = setup_logging(__name__)

class ProjectManager:
    """Manages multiple development projects."""
    
    def __init__(self, server_config: Optional[Config] = None):
        self.config = server_config or Config()
        self.projects: Dict[str, ProjectContext] = {}
        self.current_project: Optional[ProjectContext] = None
        self._setup_workspace()
        
    def _setup_workspace(self) -> None:
        """Set up workspace directory."""
        os.makedirs(self.config.server_config.workspace_dir, exist_ok=True)
        
    async def create_project(
        self,
        name: str,
        template: str = "basic",
        path: Optional[str] = None,
        **kwargs
    ) -> ProjectContext:
        """Create a new project."""
        try:
            # Generate project path if not provided
            if not path:
                path = os.path.join(
                    self.config.server_config.workspace_dir,
                    name
                )
            
            # Create project config
            project_config = ProjectConfig(
                name=name,
                path=Path(path),
                template=template,
                **kwargs
            )
            
            # Create project context
            project = ProjectContext(project_config)
            
            # Initialize project
            await project.initialize()
            # Initialize Git if enabled
            if project_config.git_enabled:
                git_manager = GitManager(path)
                await git_manager.initialize()
                await project.update_state(git_initialized=True)
            
            # Store project
            self.projects[project.id] = project
            self.current_project = project
            
            logger.info(f"Created project {name} at {path}")
            return project
            
        except Exception as e:
            raise ProjectError(f"Failed to create project: {str(e)}")
            
    async def load_project(self, path: str) -> ProjectContext:
        """Load an existing project."""
        try:
            # Verify project path exists
            if not os.path.exists(path):
                raise ProjectNotFoundError(f"Project path does not exist: {path}")
                
            # Load project config
            config_path = os.path.join(path, '.mcp', 'project.json')
            if not os.path.exists(config_path):
                raise ProjectNotFoundError(
                    f"Project configuration not found: {config_path}"
                )
                
            # Create project context
            project_config = ProjectConfig.parse_file(config_path)
            project = ProjectContext(project_config)
            
            # Store project
            self.projects[project.id] = project
            self.current_project = project
            
            logger.info(f"Loaded project from {path}")
            return project
            
        except Exception as e:
            raise ProjectError(f"Failed to load project: {str(e)}")
            
    def get_project(self, project_id: str) -> Optional[ProjectContext]:
        """Get project by ID."""
        return self.projects.get(project_id)
        
    def list_projects(self) -> List[dict]:
        """List all projects."""
        return [
            {
                "id": project_id,
                "name": project.config.name,
                "path": str(project.path),
                "template": project.config.template,
                "initialized": project.state.initialized
            }
            for project_id, project in self.projects.items()
        ]
        
    async def set_current_project(self, project_id: str) -> None:
        """Set the current active project."""
        if project := self.get_project(project_id):
            self.current_project = project
            logger.info(f"Set current project to {project.config.name}")
        else:
            raise ProjectNotFoundError(f"Project not found: {project_id}")
            
    async def delete_project(self, project_id: str, delete_files: bool = False) -> None:
        """Delete a project."""
        try:
            if project := self.get_project(project_id):
                # Clean up project resources
                await project.cleanup()
                
                # Remove from projects dict
                del self.projects[project_id]
                
                # Clear current project if it was this one
                if self.current_project and self.current_project.id == project_id:
                    self.current_project = None
                    
                # Optionally delete project files
                if delete_files and os.path.exists(project.path):
                    import shutil
                    shutil.rmtree(project.path)
                    
                logger.info(f"Deleted project {project.config.name}")
            else:
                raise ProjectNotFoundError(f"Project not found: {project_id}")
                
        except Exception as e:
            raise ProjectError(f"Failed to delete project: {str(e)}")
            
    async def cleanup(self) -> None:
        """Clean up all project resources."""
        try:
            for project in self.projects.values():
                await project.cleanup()
                
            self.projects.clear()
            self.current_project = None
            
            logger.info("Cleaned up all projects")
            
        except Exception as e:
            logger.error(f"Error during project cleanup: {str(e)}")

================
File: src/mcp_dev_server/project_manager/templates.py
================
"""Project template system for MCP Development Server."""
import os
import json
import shutil
from typing import Dict, List, Optional
from pathlib import Path

from jinja2 import Environment, FileSystemLoader
from ..utils.logging import setup_logging
from ..utils.errors import TemplateError

logger = setup_logging(__name__)

class TemplateManager:
    """Manages project templates."""
    
    def __init__(self):
        self.template_dir = os.path.join(
            os.path.dirname(__file__),
            '..',
            'resources',
            'templates'
        )
        self.env = Environment(
            loader=FileSystemLoader(self.template_dir),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
    def list_templates(self) -> List[dict]:
        """List available templates."""
        templates = []
        for template_name in os.listdir(self.template_dir):
            template_path = os.path.join(self.template_dir, template_name)
            if os.path.isdir(template_path):
                # Load template metadata
                meta_path = os.path.join(template_path, 'template.json')
                if os.path.exists(meta_path):
                    with open(meta_path) as f:
                        metadata = json.load(f)
                        templates.append({
                            "name": template_name,
                            **metadata
                        })
                        
        return templates
        
    async def apply_template(
        self,
        template_name: str,
        target_path: str,
        variables: Optional[Dict] = None
    ) -> None:
        """Apply a template to a target directory."""
        try:
            template_path = os.path.join(self.template_dir, template_name)
            if not os.path.exists(template_path):
                raise TemplateError(f"Template not found: {template_name}")
                
            # Load template configuration
            config_path = os.path.join(template_path, 'template.json')
            if os.path.exists(config_path):
                with open(config_path) as f:
                    template_config = json.load(f)
            else:
                template_config = {}
                
            # Create target directory
            os.makedirs(target_path, exist_ok=True)
            
            # Copy template files
            for root, _, files in os.walk(os.path.join(template_path, 'files')):
                rel_path = os.path.relpath(root, os.path.join(template_path, 'files'))
                target_dir = os.path.join(target_path, rel_path)
                os.makedirs(target_dir, exist_ok=True)
                
                for file in files:
                    if file.endswith('.j2'):  # Jinja2 template
                        template = self.env.get_template(
                            os.path.join(template_name, 'files', rel_path, file)
                        )
                        output = template.render(**(variables or {}))
                        
                        # Write rendered template
                        output_file = os.path.join(
                            target_dir,
                            file[:-3]  # Remove .j2 extension
                        )
                        with open(output_file, 'w') as f:
                            f.write(output)
                    else:
                        # Copy regular file
                        src = os.path.join(root, file)
                        dst = os.path.join(target_dir, file)
                        shutil.copy2(src, dst)
                        
            # Run post-template hooks if defined
            await self._run_hooks(
                template_config.get('hooks', {}),
                target_path,
                variables or {}
            )
            
            logger.info(f"Applied template {template_name} to {target_path}")
            
        except Exception as e:
            raise TemplateError(f"Failed to apply template: {str(e)}")
            
    async def _run_hooks(
        self,
        hooks: Dict,
        target_path: str,
        variables: Dict
    ) -> None:
        """Run template hooks."""
        try:
            if post_create := hooks.get('post-create'):
                if isinstance(post_create, list):
                    for cmd in post_create:
                        # Template the command
                        cmd_template = self.env.from_string(cmd)
                        command = cmd_template.render(**variables)
                        
                        # Execute command
                        import subprocess
                        subprocess.run(
                            command,
                            shell=True,
                            check=True,
                            cwd=target_path
                        )
                        
        except Exception as e:
            raise TemplateError(f"Failed to run template hooks: {str(e)}")
            
    def get_template_variables(self, template_name: str) -> Dict:
        """Get required variables for a template."""
        template_path = os.path.join(self.template_dir, template_name)
        if not os.path.exists(template_path):
            raise TemplateError(f"Template not found: {template_name}")
            
        config_path = os.path.join(template_path, 'template.json')
        if os.path.exists(config_path):
            with open(config_path) as f:
                config = json.load(f)
                return config.get('variables', {})
                
        return {}

================
File: src/mcp_dev_server/server.py
================
"""Core MCP server implementation."""
import asyncio
from typing import Dict, List, Optional, Any

from mcp.server import Server
from mcp.types import (
    Resource, Tool, Prompt, PromptArgument, TextContent,
    PromptMessage, GetPromptResult
)
from mcp.server.models import InitializationOptions
from pydantic import AnyUrl

from .project_manager.manager import ProjectManager
from .project_manager.templates import TemplateManager
from .utils.config import Config
from .utils.logging import setup_logging
from .utils.errors import MCPDevServerError

logger = setup_logging(__name__)

class MCPDevServer:
    """MCP Development Server implementation."""
    
    def __init__(self):
        # Initialize server with just the name
        self.server = Server("mcp-dev-server")
        
        # Initialize managers
        self.config = Config()
        self.project_manager = ProjectManager(self.config)
        self.template_manager = TemplateManager()
        
        # Setup request handlers
        self._setup_resource_handlers()
        self._setup_tool_handlers()
        self._setup_prompt_handlers()

    def _setup_resource_handlers(self):
        """Set up resource-related request handlers."""
        
        @self.server.list_resources()
        async def handle_list_resources() -> List[Resource]:
            """List available project resources."""
            resources = []
            
            if project := self.project_manager.current_project:
                # Project structure
                resources.append(Resource(
                    uri=f"project://{project.id}/structure",
                    name="Project Structure",
                    description="Current project file structure",
                    mimeType="application/json"
                ))
                
                # Git status if enabled
                if project.state.git_initialized:
                    resources.append(Resource(
                        uri=f"project://{project.id}/git/status",
                        name="Git Status",
                        description="Current Git repository status",
                        mimeType="application/json"
                    ))
                
            return resources
            
        @self.server.read_resource()
        async def handle_read_resource(uri: str) -> str:
            """Read a specific resource."""
            if not uri.startswith("project://"):
                raise MCPDevServerError(f"Unsupported URI scheme: {uri}")
                
            parts = uri.replace("project://", "").strip("/").split("/")
            if len(parts) < 2:
                raise MCPDevServerError(f"Invalid project URI: {uri}")
                
            project_id, resource_type = parts[0], parts[1]
            
            if project := self.project_manager.get_project(project_id):
                if resource_type == "structure":
                    return project.get_structure()
                elif resource_type == "git/status":
                    # Implement Git status resource
                    pass
                else:
                    raise MCPDevServerError(f"Unknown resource type: {resource_type}")
            else:
                raise MCPDevServerError(f"Project not found: {project_id}")
                
    def _setup_tool_handlers(self):
        """Set up tool-related request handlers."""
        
        @self.server.list_tools()
        async def handle_list_tools() -> List[Tool]:
            """List available development tools."""
            return [
                Tool(
                    name="create-project",
                    description="Create a new development project",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "template": {"type": "string"},
                            "path": {"type": "string"},
                            "description": {"type": "string"}
                        },
                        "required": ["name"]
                    }
                ),
                Tool(
                    name="load-project",
                    description="Load an existing project",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "path": {"type": "string"}
                        },
                        "required": ["path"]
                    }
                ),
                Tool(
                    name="git-commit",
                    description="Create a Git commit",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "message": {"type": "string"},
                            "files": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["message"]
                    }
                )
            ]
            
        @self.server.call_tool()
        async def handle_call_tool(name: str, arguments: Dict[str, Any]) -> List[TextContent]:
            """Handle tool execution requests."""
            try:
                if name == "create-project":
                    project = await self.project_manager.create_project(
                        name=arguments["name"],
                        template=arguments.get("template", "basic"),
                        path=arguments.get("path"),
                        description=arguments.get("description", "")
                    )
                    return [TextContent(
                        type="text",
                        text=f"Created project {project.config.name} at {project.path}"
                    )]
                    
                elif name == "load-project":
                    project = await self.project_manager.load_project(
                        arguments["path"]
                    )
                    return [TextContent(
                        type="text",
                        text=f"Loaded project {project.config.name} from {project.path}"
                    )]
                    
                elif name == "git-commit":
                    if project := self.project_manager.current_project:
                        if not project.state.git_initialized:
                            return [TextContent(
                                type="text",
                                text="Git is not initialized for this project",
                                isError=True
                            )]
                            
                        # Implement Git commit
                        pass
                    else:
                        return [TextContent(
                            type="text",
                            text="No active project",
                            isError=True
                        )]
                        
                else:
                    return [TextContent(
                        type="text",
                        text=f"Unknown tool: {name}",
                        isError=True
                    )]
                    
            except Exception as e:
                return [TextContent(
                    type="text",
                    text=f"Error: {str(e)}",
                    isError=True
                )]
                
    def _setup_prompt_handlers(self):
        """Set up prompt-related request handlers."""
        
        @self.server.list_prompts()
        async def handle_list_prompts() -> List[Prompt]:
            """List available prompts."""
            return [
                Prompt(
                    name="analyze-project",
                    description="Analyze current project structure and state",
                    arguments=[
                        PromptArgument(
                            name="focus",
                            description="Analysis focus (structure/dependencies/git)",
                            required=False
                        )
                    ]
                )
            ]
            
        @self.server.get_prompt()
        async def handle_get_prompt(name: str, arguments: Optional[Dict[str, str]] = None) -> GetPromptResult:
            """Generate prompts based on current project state."""
            if name == "analyze-project":
                if project := self.project_manager.current_project:
                    focus = arguments.get("focus", "structure") if arguments else "structure"
                    
                    if focus == "structure":
                        structure = project.get_structure()
                        return GetPromptResult(
                            messages=[
                                PromptMessage(
                                    role="user",
                                    content=TextContent(
                                        type="text",
                                        text=f"Analyze this project structure and suggest improvements:\n\n{structure}"
                                    )
                                )
                            ]
                        )
                else:
                    raise MCPDevServerError("No active project")
            else:
                raise MCPDevServerError(f"Unknown prompt: {name}")
                
    async def run(self):
        """Run the MCP server."""
        try:
            from mcp.server.stdio import stdio_server
            
            async with stdio_server() as (read_stream, write_stream):
                init_options = InitializationOptions(
                    server_name="mcp-dev-server",
                    server_version="0.1.0",
                    capabilities={
                        "resources": {},
                        "tools": {},
                        "prompts": {}
                    }
                )
                
                await self.server.run(
                    read_stream,
                    write_stream,
                    init_options
                )
                
        except Exception as e:
            logger.error(f"Server error: {str(e)}")
            raise
            
    async def cleanup(self):
        """Clean up server resources."""
        try:
            await self.project_manager.cleanup()
            logger.info("Server cleanup completed")
        except Exception as e:
            logger.error(f"Error during server cleanup: {str(e)}")

def main():
    """Entry point for the server."""
    server = MCPDevServer()
    try:
        asyncio.run(server.run())
    except KeyboardInterrupt:
        logger.info("Server shutdown requested")
        asyncio.run(server.cleanup())
    except Exception as e:
        logger.error(f"Server error: {str(e)}")
        raise

if __name__ == "__main__":
    main()

================
File: src/mcp_dev_server/utils/config.py
================
"""Configuration management for the MCP Development Server."""
import os
import json
from typing import Any, Dict, Optional
from pathlib import Path
from pydantic import BaseModel, Field

from .logging import setup_logging
from .errors import ConfigurationError

logger = setup_logging(__name__)

class ProjectConfig(BaseModel):
    """Project configuration model."""
    name: str
    path: Path
    template: str = Field(default="basic")
    git_enabled: bool = Field(default=True)
    docker_config: Dict[str, Any] = Field(default_factory=dict)
    build_config: Dict[str, Any] = Field(default_factory=dict)
    test_config: Dict[str, Any] = Field(default_factory=dict)
    dependencies: Dict[str, Dict[str, str]] = Field(default_factory=lambda: {
        "production": {},
        "development": {}
    })

    class Config:
        arbitrary_types_allowed = True

class ServerConfig(BaseModel):
    """Server configuration model."""
    host: str = Field(default="127.0.0.1")
    port: int = Field(default=8000)
    log_level: str = Field(default="INFO")
    workspace_dir: Path = Field(default=Path.home() / ".mcp-dev-server")
    max_projects: int = Field(default=10)

class Config:
    """Configuration manager."""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config_path = config_path or self._default_config_path()
        self.server_config = ServerConfig()
        self._load_config()
        
    @staticmethod
    def _default_config_path() -> str:
        """Get default configuration path."""
        config_dir = os.path.expanduser("~/.config/mcp-dev-server")
        os.makedirs(config_dir, exist_ok=True)
        return os.path.join(config_dir, "config.json")
        
    def _load_config(self) -> None:
        """Load configuration from file."""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path) as f:
                    config_data = json.load(f)
                self.server_config = ServerConfig(**config_data)
                logger.info("Loaded configuration from %s", self.config_path)
            else:
                self._save_config()
                logger.info("Created default configuration at %s", self.config_path)
        except Exception as e:
            raise ConfigurationError(f"Failed to load configuration: {str(e)}")
            
    def _save_config(self) -> None:
        """Save current configuration to file."""
        try:
            with open(self.config_path, 'w') as f:
                json.dump(
                    self.server_config.dict(),
                    f,
                    indent=2,
                    default=str
                )
        except Exception as e:
            raise ConfigurationError(f"Failed to save configuration: {str(e)}")
            
    def update_server_config(self, **kwargs) -> None:
        """Update server configuration."""
        try:
            # Update only provided fields
            for key, value in kwargs.items():
                if hasattr(self.server_config, key):
                    setattr(self.server_config, key, value)
            self._save_config()
        except Exception as e:
            raise ConfigurationError(f"Failed to update configuration: {str(e)}")

    @staticmethod
    def create_project_config(**kwargs) -> ProjectConfig:
        """Create a new project configuration."""
        try:
            return ProjectConfig(**kwargs)
        except Exception as e:
            raise ConfigurationError(f"Failed to create project configuration: {str(e)}")

================
File: src/mcp_dev_server/utils/errors.py
================
"""Custom error types for the MCP Development Server."""

class MCPDevServerError(Exception):
    """Base exception class for MCP Development Server errors."""
    pass

class ProjectError(MCPDevServerError):
    """Project-related errors."""
    pass

class ProjectNotFoundError(ProjectError):
    """Raised when a project cannot be found."""
    pass

class ProjectInitializationError(ProjectError):
    """Raised when project initialization fails."""
    pass

class FileOperationError(MCPDevServerError):
    """File system operation errors."""
    pass

class GitError(MCPDevServerError):
    """Git operation errors."""
    pass

class ConfigurationError(MCPDevServerError):
    """Configuration-related errors."""
    pass

class TemplateError(MCPDevServerError):
    """Project template errors."""
    pass
"""Add Docker-related error types."""

class DockerError(Exception):
    """Base exception for Docker-related errors."""
    pass

class ContainerError(DockerError):
    """Container operation errors."""
    pass

class VolumeError(DockerError):
    """Volume operation errors."""
    pass

class NetworkError(DockerError):
    """Network operation errors."""
    pass

class StreamError(Exception):
    """Enhanced stream-related errors."""
    pass

class SyncError(Exception):
    """Enhanced sync-related errors."""
    pass

================
File: src/mcp_dev_server/utils/logging.py
================
"""Logging configuration for the MCP Development Server."""
import logging
import sys
from typing import Optional

def setup_logging(name: str, level: Optional[str] = None) -> logging.Logger:
    """
    Set up logging configuration for the given module.
    
    Args:
        name: Module name for the logger
        level: Optional logging level (defaults to INFO)
        
    Returns:
        Configured logger instance
    """
    # Create logger
    logger = logging.getLogger(name)
    
    # Set level
    logger.setLevel(level or logging.INFO)
    
    # Create handler if none exist
    if not logger.handlers:
        handler = logging.StreamHandler(sys.stderr)
        handler.setFormatter(
            logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
        )
        logger.addHandler(handler)
    
    return logger

================
File: src/resources/templates/basic/files
================
.
 README.md.j2
 pyproject.toml.j2
 src/
    {{project_name.lower().replace('-', '_')}}/
        __init__.py.j2
 tests/
     __init__.py

Content of README.md.j2:
# {{project_name}}

{{description}}

## Installation

```bash
pip install -e .
```

## Development

```bash
# Setup development environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"

# Run tests
pytest
```

Content of pyproject.toml.j2:
[project]
name = "{{project_name}}"
version = "0.1.0"
description = "{{description}}"
requires-python = ">=3.8"
readme = "README.md"
dependencies = []

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "mypy>=1.0",
    "black>=23.0"
]

Content of src/{{project_name.lower().replace('-', '_')}}/__init__.py.j2:
"""{{project_name}} package."""

__version__ = "0.1.0"

================
File: uv.lock
================
version = 1
requires-python = ">=3.12"

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643 },
]

[[package]]
name = "anyio"
version = "4.6.2.post1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "idna" },
    { name = "sniffio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9f/09/45b9b7a6d4e45c6bcb5bf61d19e3ab87df68e0601fa8c5293de3542546cc/anyio-4.6.2.post1.tar.gz", hash = "sha256:4c8bc31ccdb51c7f7bd251f51c609e038d63e34219b44aa86e47576389880b4c", size = 173422 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e4/f5/f2b75d2fc6f1a260f340f0e7c6a060f4dd2961cc16884ed851b0d18da06a/anyio-4.6.2.post1-py3-none-any.whl", hash = "sha256:6d170c36fba3bdd840c73d3868c1e777e33676a69c3a72cf0a0d5d6d8009b61d", size = 90377 },
]

[[package]]
name = "certifi"
version = "2024.8.30"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/b0/ee/9b19140fe824b367c04c5e1b369942dd754c4c5462d5674002f75c4dedc1/certifi-2024.8.30.tar.gz", hash = "sha256:bec941d2aa8195e248a60b31ff9f0558284cf01a52591ceda73ea9afffd69fd9", size = 168507 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl", hash = "sha256:922820b53db7a7257ffbda3f597266d435245903d80737e34f8a45ff3e3230d8", size = 167321 },
]

[[package]]
name = "charset-normalizer"
version = "3.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f2/4f/e1808dc01273379acc506d18f1504eb2d299bd4131743b9fc54d7be4df1e/charset_normalizer-3.4.0.tar.gz", hash = "sha256:223217c3d4f82c3ac5e29032b3f1c2eb0fb591b72161f86d93f5719079dae93e", size = 106620 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d3/0b/4b7a70987abf9b8196845806198975b6aab4ce016632f817ad758a5aa056/charset_normalizer-3.4.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:0713f3adb9d03d49d365b70b84775d0a0d18e4ab08d12bc46baa6132ba78aaf6", size = 194445 },
    { url = "https://files.pythonhosted.org/packages/50/89/354cc56cf4dd2449715bc9a0f54f3aef3dc700d2d62d1fa5bbea53b13426/charset_normalizer-3.4.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:de7376c29d95d6719048c194a9cf1a1b0393fbe8488a22008610b0361d834ecf", size = 125275 },
    { url = "https://files.pythonhosted.org/packages/fa/44/b730e2a2580110ced837ac083d8ad222343c96bb6b66e9e4e706e4d0b6df/charset_normalizer-3.4.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:4a51b48f42d9358460b78725283f04bddaf44a9358197b889657deba38f329db", size = 119020 },
    { url = "https://files.pythonhosted.org/packages/9d/e4/9263b8240ed9472a2ae7ddc3e516e71ef46617fe40eaa51221ccd4ad9a27/charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b295729485b06c1a0683af02a9e42d2caa9db04a373dc38a6a58cdd1e8abddf1", size = 139128 },
    { url = "https://files.pythonhosted.org/packages/6b/e3/9f73e779315a54334240353eaea75854a9a690f3f580e4bd85d977cb2204/charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ee803480535c44e7f5ad00788526da7d85525cfefaf8acf8ab9a310000be4b03", size = 149277 },
    { url = "https://files.pythonhosted.org/packages/1a/cf/f1f50c2f295312edb8a548d3fa56a5c923b146cd3f24114d5adb7e7be558/charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3d59d125ffbd6d552765510e3f31ed75ebac2c7470c7274195b9161a32350284", size = 142174 },
    { url = "https://files.pythonhosted.org/packages/16/92/92a76dc2ff3a12e69ba94e7e05168d37d0345fa08c87e1fe24d0c2a42223/charset_normalizer-3.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8cda06946eac330cbe6598f77bb54e690b4ca93f593dee1568ad22b04f347c15", size = 143838 },
    { url = "https://files.pythonhosted.org/packages/a4/01/2117ff2b1dfc61695daf2babe4a874bca328489afa85952440b59819e9d7/charset_normalizer-3.4.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:07afec21bbbbf8a5cc3651aa96b980afe2526e7f048fdfb7f1014d84acc8b6d8", size = 146149 },
    { url = "https://files.pythonhosted.org/packages/f6/9b/93a332b8d25b347f6839ca0a61b7f0287b0930216994e8bf67a75d050255/charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:6b40e8d38afe634559e398cc32b1472f376a4099c75fe6299ae607e404c033b2", size = 140043 },
    { url = "https://files.pythonhosted.org/packages/ab/f6/7ac4a01adcdecbc7a7587767c776d53d369b8b971382b91211489535acf0/charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:b8dcd239c743aa2f9c22ce674a145e0a25cb1566c495928440a181ca1ccf6719", size = 148229 },
    { url = "https://files.pythonhosted.org/packages/9d/be/5708ad18161dee7dc6a0f7e6cf3a88ea6279c3e8484844c0590e50e803ef/charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:84450ba661fb96e9fd67629b93d2941c871ca86fc38d835d19d4225ff946a631", size = 151556 },
    { url = "https://files.pythonhosted.org/packages/5a/bb/3d8bc22bacb9eb89785e83e6723f9888265f3a0de3b9ce724d66bd49884e/charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:44aeb140295a2f0659e113b31cfe92c9061622cadbc9e2a2f7b8ef6b1e29ef4b", size = 149772 },
    { url = "https://files.pythonhosted.org/packages/f7/fa/d3fc622de05a86f30beea5fc4e9ac46aead4731e73fd9055496732bcc0a4/charset_normalizer-3.4.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:1db4e7fefefd0f548d73e2e2e041f9df5c59e178b4c72fbac4cc6f535cfb1565", size = 144800 },
    { url = "https://files.pythonhosted.org/packages/9a/65/bdb9bc496d7d190d725e96816e20e2ae3a6fa42a5cac99c3c3d6ff884118/charset_normalizer-3.4.0-cp312-cp312-win32.whl", hash = "sha256:5726cf76c982532c1863fb64d8c6dd0e4c90b6ece9feb06c9f202417a31f7dd7", size = 94836 },
    { url = "https://files.pythonhosted.org/packages/3e/67/7b72b69d25b89c0b3cea583ee372c43aa24df15f0e0f8d3982c57804984b/charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl", hash = "sha256:b197e7094f232959f8f20541ead1d9862ac5ebea1d58e9849c1bf979255dfac9", size = 102187 },
    { url = "https://files.pythonhosted.org/packages/f3/89/68a4c86f1a0002810a27f12e9a7b22feb198c59b2f05231349fbce5c06f4/charset_normalizer-3.4.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:dd4eda173a9fcccb5f2e2bd2a9f423d180194b1bf17cf59e3269899235b2a114", size = 194617 },
    { url = "https://files.pythonhosted.org/packages/4f/cd/8947fe425e2ab0aa57aceb7807af13a0e4162cd21eee42ef5b053447edf5/charset_normalizer-3.4.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:e9e3c4c9e1ed40ea53acf11e2a386383c3304212c965773704e4603d589343ed", size = 125310 },
    { url = "https://files.pythonhosted.org/packages/5b/f0/b5263e8668a4ee9becc2b451ed909e9c27058337fda5b8c49588183c267a/charset_normalizer-3.4.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:92a7e36b000bf022ef3dbb9c46bfe2d52c047d5e3f3343f43204263c5addc250", size = 119126 },
    { url = "https://files.pythonhosted.org/packages/ff/6e/e445afe4f7fda27a533f3234b627b3e515a1b9429bc981c9a5e2aa5d97b6/charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:54b6a92d009cbe2fb11054ba694bc9e284dad30a26757b1e372a1fdddaf21920", size = 139342 },
    { url = "https://files.pythonhosted.org/packages/a1/b2/4af9993b532d93270538ad4926c8e37dc29f2111c36f9c629840c57cd9b3/charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1ffd9493de4c922f2a38c2bf62b831dcec90ac673ed1ca182fe11b4d8e9f2a64", size = 149383 },
    { url = "https://files.pythonhosted.org/packages/fb/6f/4e78c3b97686b871db9be6f31d64e9264e889f8c9d7ab33c771f847f79b7/charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:35c404d74c2926d0287fbd63ed5d27eb911eb9e4a3bb2c6d294f3cfd4a9e0c23", size = 142214 },
    { url = "https://files.pythonhosted.org/packages/2b/c9/1c8fe3ce05d30c87eff498592c89015b19fade13df42850aafae09e94f35/charset_normalizer-3.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4796efc4faf6b53a18e3d46343535caed491776a22af773f366534056c4e1fbc", size = 144104 },
    { url = "https://files.pythonhosted.org/packages/ee/68/efad5dcb306bf37db7db338338e7bb8ebd8cf38ee5bbd5ceaaaa46f257e6/charset_normalizer-3.4.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e7fdd52961feb4c96507aa649550ec2a0d527c086d284749b2f582f2d40a2e0d", size = 146255 },
    { url = "https://files.pythonhosted.org/packages/0c/75/1ed813c3ffd200b1f3e71121c95da3f79e6d2a96120163443b3ad1057505/charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:92db3c28b5b2a273346bebb24857fda45601aef6ae1c011c0a997106581e8a88", size = 140251 },
    { url = "https://files.pythonhosted.org/packages/7d/0d/6f32255c1979653b448d3c709583557a4d24ff97ac4f3a5be156b2e6a210/charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:ab973df98fc99ab39080bfb0eb3a925181454d7c3ac8a1e695fddfae696d9e90", size = 148474 },
    { url = "https://files.pythonhosted.org/packages/ac/a0/c1b5298de4670d997101fef95b97ac440e8c8d8b4efa5a4d1ef44af82f0d/charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:4b67fdab07fdd3c10bb21edab3cbfe8cf5696f453afce75d815d9d7223fbe88b", size = 151849 },
    { url = "https://files.pythonhosted.org/packages/04/4f/b3961ba0c664989ba63e30595a3ed0875d6790ff26671e2aae2fdc28a399/charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:aa41e526a5d4a9dfcfbab0716c7e8a1b215abd3f3df5a45cf18a12721d31cb5d", size = 149781 },
    { url = "https://files.pythonhosted.org/packages/d8/90/6af4cd042066a4adad58ae25648a12c09c879efa4849c705719ba1b23d8c/charset_normalizer-3.4.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:ffc519621dce0c767e96b9c53f09c5d215578e10b02c285809f76509a3931482", size = 144970 },
    { url = "https://files.pythonhosted.org/packages/cc/67/e5e7e0cbfefc4ca79025238b43cdf8a2037854195b37d6417f3d0895c4c2/charset_normalizer-3.4.0-cp313-cp313-win32.whl", hash = "sha256:f19c1585933c82098c2a520f8ec1227f20e339e33aca8fa6f956f6691b784e67", size = 94973 },
    { url = "https://files.pythonhosted.org/packages/65/97/fc9bbc54ee13d33dc54a7fcf17b26368b18505500fc01e228c27b5222d80/charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl", hash = "sha256:707b82d19e65c9bd28b81dde95249b07bf9f5b90ebe1ef17d9b57473f8a64b7b", size = 102308 },
    { url = "https://files.pythonhosted.org/packages/bf/9b/08c0432272d77b04803958a4598a51e2a4b51c06640af8b8f0f908c18bf2/charset_normalizer-3.4.0-py3-none-any.whl", hash = "sha256:fe9f97feb71aa9896b81973a7bbada8c49501dc73e58a10fcef6663af95e5079", size = 49446 },
]

[[package]]
name = "click"
version = "8.1.7"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "platform_system == 'Windows'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/96/d3/f04c7bfcf5c1862a2a5b845c6b2b360488cf47af55dfa79c98f6a6bf98b5/click-8.1.7.tar.gz", hash = "sha256:ca9853ad459e787e2192211578cc907e7594e294c7ccc834310722b41b9ca6de", size = 336121 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl", hash = "sha256:ae74fb96c20a0277a1d615f1e4d73c8414f5a98db8b799a7931d1582f3390c28", size = 97941 },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335 },
]

[[package]]
name = "docker"
version = "7.1.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pywin32", marker = "sys_platform == 'win32'" },
    { name = "requests" },
    { name = "urllib3" },
]
sdist = { url = "https://files.pythonhosted.org/packages/91/9b/4a2ea29aeba62471211598dac5d96825bb49348fa07e906ea930394a83ce/docker-7.1.0.tar.gz", hash = "sha256:ad8c70e6e3f8926cb8a92619b832b4ea5299e2831c14284663184e200546fa6c", size = 117834 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e3/26/57c6fb270950d476074c087527a558ccb6f4436657314bfb6cdf484114c4/docker-7.1.0-py3-none-any.whl", hash = "sha256:c96b93b7f0a746f9e77d325bcfb87422a3d8bd4f03136ae8a85b37f1898d5fc0", size = 147774 },
]

[[package]]
name = "gitdb"
version = "4.0.11"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "smmap" },
]
sdist = { url = "https://files.pythonhosted.org/packages/19/0d/bbb5b5ee188dec84647a4664f3e11b06ade2bde568dbd489d9d64adef8ed/gitdb-4.0.11.tar.gz", hash = "sha256:bf5421126136d6d0af55bc1e7c1af1c397a34f5b7bd79e776cd3e89785c2b04b", size = 394469 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl", hash = "sha256:81a3407ddd2ee8df444cbacea00e2d038e40150acfa3001696fe0dcf1d3adfa4", size = 62721 },
]

[[package]]
name = "gitpython"
version = "3.1.43"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "gitdb" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b6/a1/106fd9fa2dd989b6fb36e5893961f82992cf676381707253e0bf93eb1662/GitPython-3.1.43.tar.gz", hash = "sha256:35f314a9f878467f5453cc1fee295c3e18e52f1b99f10f6cf5b1682e968a9e7c", size = 214149 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e9/bd/cc3a402a6439c15c3d4294333e13042b915bbeab54edc457c723931fed3f/GitPython-3.1.43-py3-none-any.whl", hash = "sha256:eec7ec56b92aad751f9912a73404bc02ba212a23adb2c7098ee668417051a1ff", size = 207337 },
]

[[package]]
name = "h11"
version = "0.14.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f5/38/3af3d3633a34a3316095b39c8e8fb4853a28a536e55d347bd8d8e9a14b03/h11-0.14.0.tar.gz", hash = "sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d", size = 100418 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl", hash = "sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761", size = 58259 },
]

[[package]]
name = "httpcore"
version = "1.0.7"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/6a/41/d7d0a89eb493922c37d343b607bc1b5da7f5be7e383740b4753ad8943e90/httpcore-1.0.7.tar.gz", hash = "sha256:8551cb62a169ec7162ac7be8d4817d561f60e08eaa485234898414bb5a8a0b4c", size = 85196 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl", hash = "sha256:a3fff8f43dc260d5bd363d9f9cf1830fa3a458b332856f34282de498ed420edd", size = 78551 },
]

[[package]]
name = "httpx"
version = "0.28.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/10/df/676b7cf674dd1bdc71a64ad393c89879f75e4a0ab8395165b498262ae106/httpx-0.28.0.tar.gz", hash = "sha256:0858d3bab51ba7e386637f22a61d8ccddaeec5f3fe4209da3a6168dbb91573e0", size = 141307 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8f/fb/a19866137577ba60c6d8b69498dc36be479b13ba454f691348ddf428f185/httpx-0.28.0-py3-none-any.whl", hash = "sha256:dc0b419a0cfeb6e8b34e85167c0da2671206f5095f1baa9663d23bcfd6b535fc", size = 73551 },
]

[[package]]
name = "httpx-sse"
version = "0.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/4c/60/8f4281fa9bbf3c8034fd54c0e7412e66edbab6bc74c4996bd616f8d0406e/httpx-sse-0.4.0.tar.gz", hash = "sha256:1e81a3a3070ce322add1d3529ed42eb5f70817f45ed6ec915ab753f961139721", size = 12624 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl", hash = "sha256:f329af6eae57eaa2bdfd962b42524764af68075ea87370a2de920af5341e318f", size = 7819 },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442 },
]

[[package]]
name = "inotify"
version = "0.2.10"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "nose" },
]
sdist = { url = "https://files.pythonhosted.org/packages/35/cb/6d564f8a3f25d9516298dce151670d01e43a4b3b769c1c15f40453179cd5/inotify-0.2.10.tar.gz", hash = "sha256:974a623a338482b62e16d4eb705fb863ed33ec178680fc3e96ccdf0df6c02a07", size = 9905 }

[[package]]
name = "jinja2"
version = "3.1.4"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "markupsafe" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ed/55/39036716d19cab0747a5020fc7e907f362fbf48c984b14e62127f7e68e5d/jinja2-3.1.4.tar.gz", hash = "sha256:4a3aee7acbbe7303aede8e9648d13b8bf88a429282aa6122a993f0ac800cb369", size = 240245 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl", hash = "sha256:bc5dd2abb727a5319567b7a813e6a2e7318c39f4f487cfe6c89c6f9c7d25197d", size = 133271 },
]

[[package]]
name = "markupsafe"
version = "3.0.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/b2/97/5d42485e71dfc078108a86d6de8fa46db44a1a9295e89c5d6d4a06e23a62/markupsafe-3.0.2.tar.gz", hash = "sha256:ee55d3edf80167e48ea11a923c7386f4669df67d7994554387f84e7d8b0a2bf0", size = 20537 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/22/09/d1f21434c97fc42f09d290cbb6350d44eb12f09cc62c9476effdb33a18aa/MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:9778bd8ab0a994ebf6f84c2b949e65736d5575320a17ae8984a77fab08db94cf", size = 14274 },
    { url = "https://files.pythonhosted.org/packages/6b/b0/18f76bba336fa5aecf79d45dcd6c806c280ec44538b3c13671d49099fdd0/MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:846ade7b71e3536c4e56b386c2a47adf5741d2d8b94ec9dc3e92e5e1ee1e2225", size = 12348 },
    { url = "https://files.pythonhosted.org/packages/e0/25/dd5c0f6ac1311e9b40f4af06c78efde0f3b5cbf02502f8ef9501294c425b/MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1c99d261bd2d5f6b59325c92c73df481e05e57f19837bdca8413b9eac4bd8028", size = 24149 },
    { url = "https://files.pythonhosted.org/packages/f3/f0/89e7aadfb3749d0f52234a0c8c7867877876e0a20b60e2188e9850794c17/MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e17c96c14e19278594aa4841ec148115f9c7615a47382ecb6b82bd8fea3ab0c8", size = 23118 },
    { url = "https://files.pythonhosted.org/packages/d5/da/f2eeb64c723f5e3777bc081da884b414671982008c47dcc1873d81f625b6/MarkupSafe-3.0.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:88416bd1e65dcea10bc7569faacb2c20ce071dd1f87539ca2ab364bf6231393c", size = 22993 },
    { url = "https://files.pythonhosted.org/packages/da/0e/1f32af846df486dce7c227fe0f2398dc7e2e51d4a370508281f3c1c5cddc/MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:2181e67807fc2fa785d0592dc2d6206c019b9502410671cc905d132a92866557", size = 24178 },
    { url = "https://files.pythonhosted.org/packages/c4/f6/bb3ca0532de8086cbff5f06d137064c8410d10779c4c127e0e47d17c0b71/MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:52305740fe773d09cffb16f8ed0427942901f00adedac82ec8b67752f58a1b22", size = 23319 },
    { url = "https://files.pythonhosted.org/packages/a2/82/8be4c96ffee03c5b4a034e60a31294daf481e12c7c43ab8e34a1453ee48b/MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:ad10d3ded218f1039f11a75f8091880239651b52e9bb592ca27de44eed242a48", size = 23352 },
    { url = "https://files.pythonhosted.org/packages/51/ae/97827349d3fcffee7e184bdf7f41cd6b88d9919c80f0263ba7acd1bbcb18/MarkupSafe-3.0.2-cp312-cp312-win32.whl", hash = "sha256:0f4ca02bea9a23221c0182836703cbf8930c5e9454bacce27e767509fa286a30", size = 15097 },
    { url = "https://files.pythonhosted.org/packages/c1/80/a61f99dc3a936413c3ee4e1eecac96c0da5ed07ad56fd975f1a9da5bc630/MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:8e06879fc22a25ca47312fbe7c8264eb0b662f6db27cb2d3bbbc74b1df4b9b87", size = 15601 },
    { url = "https://files.pythonhosted.org/packages/83/0e/67eb10a7ecc77a0c2bbe2b0235765b98d164d81600746914bebada795e97/MarkupSafe-3.0.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ba9527cdd4c926ed0760bc301f6728ef34d841f405abf9d4f959c478421e4efd", size = 14274 },
    { url = "https://files.pythonhosted.org/packages/2b/6d/9409f3684d3335375d04e5f05744dfe7e9f120062c9857df4ab490a1031a/MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:f8b3d067f2e40fe93e1ccdd6b2e1d16c43140e76f02fb1319a05cf2b79d99430", size = 12352 },
    { url = "https://files.pythonhosted.org/packages/d2/f5/6eadfcd3885ea85fe2a7c128315cc1bb7241e1987443d78c8fe712d03091/MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:569511d3b58c8791ab4c2e1285575265991e6d8f8700c7be0e88f86cb0672094", size = 24122 },
    { url = "https://files.pythonhosted.org/packages/0c/91/96cf928db8236f1bfab6ce15ad070dfdd02ed88261c2afafd4b43575e9e9/MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:15ab75ef81add55874e7ab7055e9c397312385bd9ced94920f2802310c930396", size = 23085 },
    { url = "https://files.pythonhosted.org/packages/c2/cf/c9d56af24d56ea04daae7ac0940232d31d5a8354f2b457c6d856b2057d69/MarkupSafe-3.0.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f3818cb119498c0678015754eba762e0d61e5b52d34c8b13d770f0719f7b1d79", size = 22978 },
    { url = "https://files.pythonhosted.org/packages/2a/9f/8619835cd6a711d6272d62abb78c033bda638fdc54c4e7f4272cf1c0962b/MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:cdb82a876c47801bb54a690c5ae105a46b392ac6099881cdfb9f6e95e4014c6a", size = 24208 },
    { url = "https://files.pythonhosted.org/packages/f9/bf/176950a1792b2cd2102b8ffeb5133e1ed984547b75db47c25a67d3359f77/MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:cabc348d87e913db6ab4aa100f01b08f481097838bdddf7c7a84b7575b7309ca", size = 23357 },
    { url = "https://files.pythonhosted.org/packages/ce/4f/9a02c1d335caabe5c4efb90e1b6e8ee944aa245c1aaaab8e8a618987d816/MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:444dcda765c8a838eaae23112db52f1efaf750daddb2d9ca300bcae1039adc5c", size = 23344 },
    { url = "https://files.pythonhosted.org/packages/ee/55/c271b57db36f748f0e04a759ace9f8f759ccf22b4960c270c78a394f58be/MarkupSafe-3.0.2-cp313-cp313-win32.whl", hash = "sha256:bcf3e58998965654fdaff38e58584d8937aa3096ab5354d493c77d1fdd66d7a1", size = 15101 },
    { url = "https://files.pythonhosted.org/packages/29/88/07df22d2dd4df40aba9f3e402e6dc1b8ee86297dddbad4872bd5e7b0094f/MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:e6a2a455bd412959b57a172ce6328d2dd1f01cb2135efda2e4576e8a23fa3b0f", size = 15603 },
    { url = "https://files.pythonhosted.org/packages/62/6a/8b89d24db2d32d433dffcd6a8779159da109842434f1dd2f6e71f32f738c/MarkupSafe-3.0.2-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:b5a6b3ada725cea8a5e634536b1b01c30bcdcd7f9c6fff4151548d5bf6b3a36c", size = 14510 },
    { url = "https://files.pythonhosted.org/packages/7a/06/a10f955f70a2e5a9bf78d11a161029d278eeacbd35ef806c3fd17b13060d/MarkupSafe-3.0.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:a904af0a6162c73e3edcb969eeeb53a63ceeb5d8cf642fade7d39e7963a22ddb", size = 12486 },
    { url = "https://files.pythonhosted.org/packages/34/cf/65d4a571869a1a9078198ca28f39fba5fbb910f952f9dbc5220afff9f5e6/MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4aa4e5faecf353ed117801a068ebab7b7e09ffb6e1d5e412dc852e0da018126c", size = 25480 },
    { url = "https://files.pythonhosted.org/packages/0c/e3/90e9651924c430b885468b56b3d597cabf6d72be4b24a0acd1fa0e12af67/MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c0ef13eaeee5b615fb07c9a7dadb38eac06a0608b41570d8ade51c56539e509d", size = 23914 },
    { url = "https://files.pythonhosted.org/packages/66/8c/6c7cf61f95d63bb866db39085150df1f2a5bd3335298f14a66b48e92659c/MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d16a81a06776313e817c951135cf7340a3e91e8c1ff2fac444cfd75fffa04afe", size = 23796 },
    { url = "https://files.pythonhosted.org/packages/bb/35/cbe9238ec3f47ac9a7c8b3df7a808e7cb50fe149dc7039f5f454b3fba218/MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:6381026f158fdb7c72a168278597a5e3a5222e83ea18f543112b2662a9b699c5", size = 25473 },
    { url = "https://files.pythonhosted.org/packages/e6/32/7621a4382488aa283cc05e8984a9c219abad3bca087be9ec77e89939ded9/MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:3d79d162e7be8f996986c064d1c7c817f6df3a77fe3d6859f6f9e7be4b8c213a", size = 24114 },
    { url = "https://files.pythonhosted.org/packages/0d/80/0985960e4b89922cb5a0bac0ed39c5b96cbc1a536a99f30e8c220a996ed9/MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:131a3c7689c85f5ad20f9f6fb1b866f402c445b220c19fe4308c0b147ccd2ad9", size = 24098 },
    { url = "https://files.pythonhosted.org/packages/82/78/fedb03c7d5380df2427038ec8d973587e90561b2d90cd472ce9254cf348b/MarkupSafe-3.0.2-cp313-cp313t-win32.whl", hash = "sha256:ba8062ed2cf21c07a9e295d5b8a2a5ce678b913b45fdf68c32d95d6c1291e0b6", size = 15208 },
    { url = "https://files.pythonhosted.org/packages/4f/65/6079a46068dfceaeabb5dcad6d674f5f5c61a6fa5673746f42a9f4c233b3/MarkupSafe-3.0.2-cp313-cp313t-win_amd64.whl", hash = "sha256:e444a31f8db13eb18ada366ab3cf45fd4b31e4db1236a4448f68778c1d1a5a2f", size = 15739 },
]

[[package]]
name = "mcp"
version = "1.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "httpx" },
    { name = "httpx-sse" },
    { name = "pydantic" },
    { name = "sse-starlette" },
    { name = "starlette" },
]
sdist = { url = "https://files.pythonhosted.org/packages/97/de/a9ec0a1b6439f90ea59f89004bb2e7ec6890dfaeef809751d9e6577dca7e/mcp-1.0.0.tar.gz", hash = "sha256:dba51ce0b5c6a80e25576f606760c49a91ee90210fed805b530ca165d3bbc9b7", size = 82891 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/56/89/900c0c8445ec001d3725e475fc553b0feb2e8a51be018f3bb7de51e683db/mcp-1.0.0-py3-none-any.whl", hash = "sha256:bbe70ffa3341cd4da78b5eb504958355c68381fb29971471cea1e642a2af5b8a", size = 36361 },
]

[[package]]
name = "mcp-dev-server"
version = "0.1.0"
source = { editable = "." }
dependencies = [
    { name = "anyio" },
    { name = "docker" },
    { name = "gitpython" },
    { name = "inotify" },
    { name = "jinja2" },
    { name = "mcp" },
    { name = "pydantic" },
    { name = "watchdog" },
]

[package.metadata]
requires-dist = [
    { name = "anyio", specifier = ">=4.0.0" },
    { name = "docker", specifier = ">=7.0.0" },
    { name = "gitpython", specifier = ">=3.1.0" },
    { name = "inotify", specifier = ">=0.2.10" },
    { name = "jinja2", specifier = ">=3.0.0" },
    { name = "mcp", specifier = ">=1.0.0" },
    { name = "pydantic", specifier = ">=2.0.0" },
    { name = "watchdog", specifier = ">=2.1.0" },
]

[[package]]
name = "nose"
version = "1.3.7"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/58/a5/0dc93c3ec33f4e281849523a5a913fa1eea9a3068acfa754d44d88107a44/nose-1.3.7.tar.gz", hash = "sha256:f1bffef9cbc82628f6e7d7b40d7e255aefaa1adb6a1b1d26c69a8b79e6208a98", size = 280488 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl", hash = "sha256:9ff7c6cc443f8c51994b34a667bbcf45afd6d945be7477b52e97516fd17c53ac", size = 154731 },
]

[[package]]
name = "pydantic"
version = "2.10.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/41/86/a03390cb12cf64e2a8df07c267f3eb8d5035e0f9a04bb20fb79403d2a00e/pydantic-2.10.2.tar.gz", hash = "sha256:2bc2d7f17232e0841cbba4641e65ba1eb6fafb3a08de3a091ff3ce14a197c4fa", size = 785401 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d5/74/da832196702d0c56eb86b75bfa346db9238617e29b0b7ee3b8b4eccfe654/pydantic-2.10.2-py3-none-any.whl", hash = "sha256:cfb96e45951117c3024e6b67b25cdc33a3cb7b2fa62e239f7af1378358a1d99e", size = 456364 },
]

[[package]]
name = "pydantic-core"
version = "2.27.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a6/9f/7de1f19b6aea45aeb441838782d68352e71bfa98ee6fa048d5041991b33e/pydantic_core-2.27.1.tar.gz", hash = "sha256:62a763352879b84aa31058fc931884055fd75089cccbd9d58bb6afd01141b235", size = 412785 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/be/51/2e9b3788feb2aebff2aa9dfbf060ec739b38c05c46847601134cc1fed2ea/pydantic_core-2.27.1-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:9cbd94fc661d2bab2bc702cddd2d3370bbdcc4cd0f8f57488a81bcce90c7a54f", size = 1895239 },
    { url = "https://files.pythonhosted.org/packages/7b/9e/f8063952e4a7d0127f5d1181addef9377505dcce3be224263b25c4f0bfd9/pydantic_core-2.27.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:5f8c4718cd44ec1580e180cb739713ecda2bdee1341084c1467802a417fe0f02", size = 1805070 },
    { url = "https://files.pythonhosted.org/packages/2c/9d/e1d6c4561d262b52e41b17a7ef8301e2ba80b61e32e94520271029feb5d8/pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:15aae984e46de8d376df515f00450d1522077254ef6b7ce189b38ecee7c9677c", size = 1828096 },
    { url = "https://files.pythonhosted.org/packages/be/65/80ff46de4266560baa4332ae3181fffc4488ea7d37282da1a62d10ab89a4/pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:1ba5e3963344ff25fc8c40da90f44b0afca8cfd89d12964feb79ac1411a260ac", size = 1857708 },
    { url = "https://files.pythonhosted.org/packages/d5/ca/3370074ad758b04d9562b12ecdb088597f4d9d13893a48a583fb47682cdf/pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:992cea5f4f3b29d6b4f7f1726ed8ee46c8331c6b4eed6db5b40134c6fe1768bb", size = 2037751 },
    { url = "https://files.pythonhosted.org/packages/b1/e2/4ab72d93367194317b99d051947c071aef6e3eb95f7553eaa4208ecf9ba4/pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0325336f348dbee6550d129b1627cb8f5351a9dc91aad141ffb96d4937bd9529", size = 2733863 },
    { url = "https://files.pythonhosted.org/packages/8a/c6/8ae0831bf77f356bb73127ce5a95fe115b10f820ea480abbd72d3cc7ccf3/pydantic_core-2.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7597c07fbd11515f654d6ece3d0e4e5093edc30a436c63142d9a4b8e22f19c35", size = 2161161 },
    { url = "https://files.pythonhosted.org/packages/f1/f4/b2fe73241da2429400fc27ddeaa43e35562f96cf5b67499b2de52b528cad/pydantic_core-2.27.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:3bbd5d8cc692616d5ef6fbbbd50dbec142c7e6ad9beb66b78a96e9c16729b089", size = 1993294 },
    { url = "https://files.pythonhosted.org/packages/77/29/4bb008823a7f4cc05828198153f9753b3bd4c104d93b8e0b1bfe4e187540/pydantic_core-2.27.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:dc61505e73298a84a2f317255fcc72b710b72980f3a1f670447a21efc88f8381", size = 2001468 },
    { url = "https://files.pythonhosted.org/packages/f2/a9/0eaceeba41b9fad851a4107e0cf999a34ae8f0d0d1f829e2574f3d8897b0/pydantic_core-2.27.1-cp312-cp312-musllinux_1_1_armv7l.whl", hash = "sha256:e1f735dc43da318cad19b4173dd1ffce1d84aafd6c9b782b3abc04a0d5a6f5bb", size = 2091413 },
    { url = "https://files.pythonhosted.org/packages/d8/36/eb8697729725bc610fd73940f0d860d791dc2ad557faaefcbb3edbd2b349/pydantic_core-2.27.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:f4e5658dbffe8843a0f12366a4c2d1c316dbe09bb4dfbdc9d2d9cd6031de8aae", size = 2154735 },
    { url = "https://files.pythonhosted.org/packages/52/e5/4f0fbd5c5995cc70d3afed1b5c754055bb67908f55b5cb8000f7112749bf/pydantic_core-2.27.1-cp312-none-win32.whl", hash = "sha256:672ebbe820bb37988c4d136eca2652ee114992d5d41c7e4858cdd90ea94ffe5c", size = 1833633 },
    { url = "https://files.pythonhosted.org/packages/ee/f2/c61486eee27cae5ac781305658779b4a6b45f9cc9d02c90cb21b940e82cc/pydantic_core-2.27.1-cp312-none-win_amd64.whl", hash = "sha256:66ff044fd0bb1768688aecbe28b6190f6e799349221fb0de0e6f4048eca14c16", size = 1986973 },
    { url = "https://files.pythonhosted.org/packages/df/a6/e3f12ff25f250b02f7c51be89a294689d175ac76e1096c32bf278f29ca1e/pydantic_core-2.27.1-cp312-none-win_arm64.whl", hash = "sha256:9a3b0793b1bbfd4146304e23d90045f2a9b5fd5823aa682665fbdaf2a6c28f3e", size = 1883215 },
    { url = "https://files.pythonhosted.org/packages/0f/d6/91cb99a3c59d7b072bded9959fbeab0a9613d5a4935773c0801f1764c156/pydantic_core-2.27.1-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:f216dbce0e60e4d03e0c4353c7023b202d95cbaeff12e5fd2e82ea0a66905073", size = 1895033 },
    { url = "https://files.pythonhosted.org/packages/07/42/d35033f81a28b27dedcade9e967e8a40981a765795c9ebae2045bcef05d3/pydantic_core-2.27.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:a2e02889071850bbfd36b56fd6bc98945e23670773bc7a76657e90e6b6603c08", size = 1807542 },
    { url = "https://files.pythonhosted.org/packages/41/c2/491b59e222ec7e72236e512108ecad532c7f4391a14e971c963f624f7569/pydantic_core-2.27.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:42b0e23f119b2b456d07ca91b307ae167cc3f6c846a7b169fca5326e32fdc6cf", size = 1827854 },
    { url = "https://files.pythonhosted.org/packages/e3/f3/363652651779113189cefdbbb619b7b07b7a67ebb6840325117cc8cc3460/pydantic_core-2.27.1-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:764be71193f87d460a03f1f7385a82e226639732214b402f9aa61f0d025f0737", size = 1857389 },
    { url = "https://files.pythonhosted.org/packages/5f/97/be804aed6b479af5a945daec7538d8bf358d668bdadde4c7888a2506bdfb/pydantic_core-2.27.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1c00666a3bd2f84920a4e94434f5974d7bbc57e461318d6bb34ce9cdbbc1f6b2", size = 2037934 },
    { url = "https://files.pythonhosted.org/packages/42/01/295f0bd4abf58902917e342ddfe5f76cf66ffabfc57c2e23c7681a1a1197/pydantic_core-2.27.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3ccaa88b24eebc0f849ce0a4d09e8a408ec5a94afff395eb69baf868f5183107", size = 2735176 },
    { url = "https://files.pythonhosted.org/packages/9d/a0/cd8e9c940ead89cc37812a1a9f310fef59ba2f0b22b4e417d84ab09fa970/pydantic_core-2.27.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c65af9088ac534313e1963443d0ec360bb2b9cba6c2909478d22c2e363d98a51", size = 2160720 },
    { url = "https://files.pythonhosted.org/packages/73/ae/9d0980e286627e0aeca4c352a60bd760331622c12d576e5ea4441ac7e15e/pydantic_core-2.27.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:206b5cf6f0c513baffaeae7bd817717140770c74528f3e4c3e1cec7871ddd61a", size = 1992972 },
    { url = "https://files.pythonhosted.org/packages/bf/ba/ae4480bc0292d54b85cfb954e9d6bd226982949f8316338677d56541b85f/pydantic_core-2.27.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:062f60e512fc7fff8b8a9d680ff0ddaaef0193dba9fa83e679c0c5f5fbd018bc", size = 2001477 },
    { url = "https://files.pythonhosted.org/packages/55/b7/e26adf48c2f943092ce54ae14c3c08d0d221ad34ce80b18a50de8ed2cba8/pydantic_core-2.27.1-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:a0697803ed7d4af5e4c1adf1670af078f8fcab7a86350e969f454daf598c4960", size = 2091186 },
    { url = "https://files.pythonhosted.org/packages/ba/cc/8491fff5b608b3862eb36e7d29d36a1af1c945463ca4c5040bf46cc73f40/pydantic_core-2.27.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:58ca98a950171f3151c603aeea9303ef6c235f692fe555e883591103da709b23", size = 2154429 },
    { url = "https://files.pythonhosted.org/packages/78/d8/c080592d80edd3441ab7f88f865f51dae94a157fc64283c680e9f32cf6da/pydantic_core-2.27.1-cp313-none-win32.whl", hash = "sha256:8065914ff79f7eab1599bd80406681f0ad08f8e47c880f17b416c9f8f7a26d05", size = 1833713 },
    { url = "https://files.pythonhosted.org/packages/83/84/5ab82a9ee2538ac95a66e51f6838d6aba6e0a03a42aa185ad2fe404a4e8f/pydantic_core-2.27.1-cp313-none-win_amd64.whl", hash = "sha256:ba630d5e3db74c79300d9a5bdaaf6200172b107f263c98a0539eeecb857b2337", size = 1987897 },
    { url = "https://files.pythonhosted.org/packages/df/c3/b15fb833926d91d982fde29c0624c9f225da743c7af801dace0d4e187e71/pydantic_core-2.27.1-cp313-none-win_arm64.whl", hash = "sha256:45cf8588c066860b623cd11c4ba687f8d7175d5f7ef65f7129df8a394c502de5", size = 1882983 },
]

[[package]]
name = "pywin32"
version = "308"
source = { registry = "https://pypi.org/simple" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/00/7c/d00d6bdd96de4344e06c4afbf218bc86b54436a94c01c71a8701f613aa56/pywin32-308-cp312-cp312-win32.whl", hash = "sha256:587f3e19696f4bf96fde9d8a57cec74a57021ad5f204c9e627e15c33ff568897", size = 5939729 },
    { url = "https://files.pythonhosted.org/packages/21/27/0c8811fbc3ca188f93b5354e7c286eb91f80a53afa4e11007ef661afa746/pywin32-308-cp312-cp312-win_amd64.whl", hash = "sha256:00b3e11ef09ede56c6a43c71f2d31857cf7c54b0ab6e78ac659497abd2834f47", size = 6543015 },
    { url = "https://files.pythonhosted.org/packages/9d/0f/d40f8373608caed2255781a3ad9a51d03a594a1248cd632d6a298daca693/pywin32-308-cp312-cp312-win_arm64.whl", hash = "sha256:9b4de86c8d909aed15b7011182c8cab38c8850de36e6afb1f0db22b8959e3091", size = 7976033 },
    { url = "https://files.pythonhosted.org/packages/a9/a4/aa562d8935e3df5e49c161b427a3a2efad2ed4e9cf81c3de636f1fdddfd0/pywin32-308-cp313-cp313-win32.whl", hash = "sha256:1c44539a37a5b7b21d02ab34e6a4d314e0788f1690d65b48e9b0b89f31abbbed", size = 5938579 },
    { url = "https://files.pythonhosted.org/packages/c7/50/b0efb8bb66210da67a53ab95fd7a98826a97ee21f1d22949863e6d588b22/pywin32-308-cp313-cp313-win_amd64.whl", hash = "sha256:fd380990e792eaf6827fcb7e187b2b4b1cede0585e3d0c9e84201ec27b9905e4", size = 6542056 },
    { url = "https://files.pythonhosted.org/packages/26/df/2b63e3e4f2df0224f8aaf6d131f54fe4e8c96400eb9df563e2aae2e1a1f9/pywin32-308-cp313-cp313-win_arm64.whl", hash = "sha256:ef313c46d4c18dfb82a2431e3051ac8f112ccee1a34f29c263c583c568db63cd", size = 7974986 },
]

[[package]]
name = "requests"
version = "2.32.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "charset-normalizer" },
    { name = "idna" },
    { name = "urllib3" },
]
sdist = { url = "https://files.pythonhosted.org/packages/63/70/2bf7780ad2d390a8d301ad0b550f1581eadbd9a20f896afe06353c2a2913/requests-2.32.3.tar.gz", hash = "sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760", size = 131218 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl", hash = "sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6", size = 64928 },
]

[[package]]
name = "smmap"
version = "5.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/88/04/b5bf6d21dc4041000ccba7eb17dd3055feb237e7ffc2c20d3fae3af62baa/smmap-5.0.1.tar.gz", hash = "sha256:dceeb6c0028fdb6734471eb07c0cd2aae706ccaecab45965ee83f11c8d3b1f62", size = 22291 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl", hash = "sha256:e6d8668fa5f93e706934a62d7b4db19c8d9eb8cf2adbb75ef1b675aa332b69da", size = 24282 },
]

[[package]]
name = "sniffio"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/87/a6771e1546d97e7e041b6ae58d80074f81b7d5121207425c964ddf5cfdbd/sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc", size = 20372 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2", size = 10235 },
]

[[package]]
name = "sse-starlette"
version = "2.1.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "starlette" },
    { name = "uvicorn" },
]
sdist = { url = "https://files.pythonhosted.org/packages/72/fc/56ab9f116b2133521f532fce8d03194cf04dcac25f583cf3d839be4c0496/sse_starlette-2.1.3.tar.gz", hash = "sha256:9cd27eb35319e1414e3d2558ee7414487f9529ce3b3cf9b21434fd110e017169", size = 19678 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/52/aa/36b271bc4fa1d2796311ee7c7283a3a1c348bad426d37293609ca4300eef/sse_starlette-2.1.3-py3-none-any.whl", hash = "sha256:8ec846438b4665b9e8c560fcdea6bc8081a3abf7942faa95e5a744999d219772", size = 9383 },
]

[[package]]
name = "starlette"
version = "0.41.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/1a/4c/9b5764bd22eec91c4039ef4c55334e9187085da2d8a2df7bd570869aae18/starlette-0.41.3.tar.gz", hash = "sha256:0e4ab3d16522a255be6b28260b938eae2482f98ce5cc934cb08dce8dc3ba5835", size = 2574159 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl", hash = "sha256:44cedb2b7c77a9de33a8b74b2b90e9f50d11fcf25d8270ea525ad71a25374ff7", size = 73225 },
]

[[package]]
name = "typing-extensions"
version = "4.12.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/df/db/f35a00659bc03fec321ba8bce9420de607a1d37f8342eee1863174c69557/typing_extensions-4.12.2.tar.gz", hash = "sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8", size = 85321 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl", hash = "sha256:04e5ca0351e0f3f85c6853954072df659d0d13fac324d0072316b67d7794700d", size = 37438 },
]

[[package]]
name = "urllib3"
version = "2.2.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ed/63/22ba4ebfe7430b76388e7cd448d5478814d3032121827c12a2cc287e2260/urllib3-2.2.3.tar.gz", hash = "sha256:e7d814a81dad81e6caf2ec9fdedb284ecc9c73076b62654547cc64ccdcae26e9", size = 300677 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ce/d9/5f4c13cecde62396b0d3fe530a50ccea91e7dfc1ccf0e09c228841bb5ba8/urllib3-2.2.3-py3-none-any.whl", hash = "sha256:ca899ca043dcb1bafa3e262d73aa25c465bfb49e0bd9dd5d59f1d0acba2f8fac", size = 126338 },
]

[[package]]
name = "uvicorn"
version = "0.32.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "click" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/6a/3c/21dba3e7d76138725ef307e3d7ddd29b763119b3aa459d02cc05fefcff75/uvicorn-0.32.1.tar.gz", hash = "sha256:ee9519c246a72b1c084cea8d3b44ed6026e78a4a309cbedae9c37e4cb9fbb175", size = 77630 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/50/c1/2d27b0a15826c2b71dcf6e2f5402181ef85acf439617bb2f1453125ce1f3/uvicorn-0.32.1-py3-none-any.whl", hash = "sha256:82ad92fd58da0d12af7482ecdb5f2470a04c9c9a53ced65b9bbb4a205377602e", size = 63828 },
]

[[package]]
name = "watchdog"
version = "6.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/db/7d/7f3d619e951c88ed75c6037b246ddcf2d322812ee8ea189be89511721d54/watchdog-6.0.0.tar.gz", hash = "sha256:9ddf7c82fda3ae8e24decda1338ede66e1c99883db93711d8fb941eaa2d8c282", size = 131220 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/39/ea/3930d07dafc9e286ed356a679aa02d777c06e9bfd1164fa7c19c288a5483/watchdog-6.0.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:bdd4e6f14b8b18c334febb9c4425a878a2ac20efd1e0b231978e7b150f92a948", size = 96471 },
    { url = "https://files.pythonhosted.org/packages/12/87/48361531f70b1f87928b045df868a9fd4e253d9ae087fa4cf3f7113be363/watchdog-6.0.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:c7c15dda13c4eb00d6fb6fc508b3c0ed88b9d5d374056b239c4ad1611125c860", size = 88449 },
    { url = "https://files.pythonhosted.org/packages/5b/7e/8f322f5e600812e6f9a31b75d242631068ca8f4ef0582dd3ae6e72daecc8/watchdog-6.0.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:6f10cb2d5902447c7d0da897e2c6768bca89174d0c6e1e30abec5421af97a5b0", size = 89054 },
    { url = "https://files.pythonhosted.org/packages/68/98/b0345cabdce2041a01293ba483333582891a3bd5769b08eceb0d406056ef/watchdog-6.0.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:490ab2ef84f11129844c23fb14ecf30ef3d8a6abafd3754a6f75ca1e6654136c", size = 96480 },
    { url = "https://files.pythonhosted.org/packages/85/83/cdf13902c626b28eedef7ec4f10745c52aad8a8fe7eb04ed7b1f111ca20e/watchdog-6.0.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:76aae96b00ae814b181bb25b1b98076d5fc84e8a53cd8885a318b42b6d3a5134", size = 88451 },
    { url = "https://files.pythonhosted.org/packages/fe/c4/225c87bae08c8b9ec99030cd48ae9c4eca050a59bf5c2255853e18c87b50/watchdog-6.0.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:a175f755fc2279e0b7312c0035d52e27211a5bc39719dd529625b1930917345b", size = 89057 },
    { url = "https://files.pythonhosted.org/packages/a9/c7/ca4bf3e518cb57a686b2feb4f55a1892fd9a3dd13f470fca14e00f80ea36/watchdog-6.0.0-py3-none-manylinux2014_aarch64.whl", hash = "sha256:7607498efa04a3542ae3e05e64da8202e58159aa1fa4acddf7678d34a35d4f13", size = 79079 },
    { url = "https://files.pythonhosted.org/packages/5c/51/d46dc9332f9a647593c947b4b88e2381c8dfc0942d15b8edc0310fa4abb1/watchdog-6.0.0-py3-none-manylinux2014_armv7l.whl", hash = "sha256:9041567ee8953024c83343288ccc458fd0a2d811d6a0fd68c4c22609e3490379", size = 79078 },
    { url = "https://files.pythonhosted.org/packages/d4/57/04edbf5e169cd318d5f07b4766fee38e825d64b6913ca157ca32d1a42267/watchdog-6.0.0-py3-none-manylinux2014_i686.whl", hash = "sha256:82dc3e3143c7e38ec49d61af98d6558288c415eac98486a5c581726e0737c00e", size = 79076 },
    { url = "https://files.pythonhosted.org/packages/ab/cc/da8422b300e13cb187d2203f20b9253e91058aaf7db65b74142013478e66/watchdog-6.0.0-py3-none-manylinux2014_ppc64.whl", hash = "sha256:212ac9b8bf1161dc91bd09c048048a95ca3a4c4f5e5d4a7d1b1a7d5752a7f96f", size = 79077 },
    { url = "https://files.pythonhosted.org/packages/2c/3b/b8964e04ae1a025c44ba8e4291f86e97fac443bca31de8bd98d3263d2fcf/watchdog-6.0.0-py3-none-manylinux2014_ppc64le.whl", hash = "sha256:e3df4cbb9a450c6d49318f6d14f4bbc80d763fa587ba46ec86f99f9e6876bb26", size = 79078 },
    { url = "https://files.pythonhosted.org/packages/62/ae/a696eb424bedff7407801c257d4b1afda455fe40821a2be430e173660e81/watchdog-6.0.0-py3-none-manylinux2014_s390x.whl", hash = "sha256:2cce7cfc2008eb51feb6aab51251fd79b85d9894e98ba847408f662b3395ca3c", size = 79077 },
    { url = "https://files.pythonhosted.org/packages/b5/e8/dbf020b4d98251a9860752a094d09a65e1b436ad181faf929983f697048f/watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl", hash = "sha256:20ffe5b202af80ab4266dcd3e91aae72bf2da48c0d33bdb15c66658e685e94e2", size = 79078 },
    { url = "https://files.pythonhosted.org/packages/07/f6/d0e5b343768e8bcb4cda79f0f2f55051bf26177ecd5651f84c07567461cf/watchdog-6.0.0-py3-none-win32.whl", hash = "sha256:07df1fdd701c5d4c8e55ef6cf55b8f0120fe1aef7ef39a1c6fc6bc2e606d517a", size = 79065 },
    { url = "https://files.pythonhosted.org/packages/db/d9/c495884c6e548fce18a8f40568ff120bc3a4b7b99813081c8ac0c936fa64/watchdog-6.0.0-py3-none-win_amd64.whl", hash = "sha256:cbafb470cf848d93b5d013e2ecb245d4aa1c8fd0504e863ccefa32445359d680", size = 79070 },
    { url = "https://files.pythonhosted.org/packages/33/e8/e40370e6d74ddba47f002a32919d91310d6074130fe4e17dabcafc15cbf1/watchdog-6.0.0-py3-none-win_ia64.whl", hash = "sha256:a1914259fa9e1454315171103c6a30961236f508b9b623eae470268bbcc6a22f", size = 79067 },
]
